{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d485cd24-4c8d-4b30-aeaf-1201997f7bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using cuda\n",
      "seed: 2419200\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from swadist.data import get_dataloaders\n",
    "from swadist.train import Trainer\n",
    "from swadist.optim import LinearPolyLR\n",
    "from swadist.models import ResNet\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "print(f'Using {device}')\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "seed = int((datetime.date.today() - datetime.date(2022, 4, 11)).total_seconds())\n",
    "torch.manual_seed(seed)\n",
    "print(f'seed: {seed}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ca6a7-4f78-4ccf-b5be-ecfb07c4f14b",
   "metadata": {},
   "source": [
    "### SGD training\n",
    "\n",
    "We train ResNet-8, using the optimal hyperparameters given in [Shallue et al. 2019](http://arxiv.org/abs/1811.03600) via SGD with Nesterov momentum and a linearly-decreasing learning rate schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03b0baf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(1, 64, kernel_size=3)\n",
    "        self.conv_2 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        self.bn_1 = nn.BatchNorm2d(64)\n",
    "        self.conv_3 = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.conv_4 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.bn_2 = nn.BatchNorm2d(128)\n",
    "        self.conv_5 = nn.Conv2d(128, 256, kernel_size=3)\n",
    "        self.bn_3 = nn.BatchNorm2d(256)\n",
    "        self.fc_1 = nn.Linear(256, 512)\n",
    "        self.fc_2 = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        # x = self.bn_1(x)\n",
    "\n",
    "        x = F.relu(self.conv_3(x))\n",
    "        x = F.relu(self.conv_4(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        # x = self.bn_2(x)\n",
    "\n",
    "        x = F.relu(self.conv_5(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        # x = self.bn_3(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        # print(x.size())\n",
    "\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x))\n",
    "        x = F.softmax(x, dim=-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7e50eaf-16d5-45a2-a0f5-12d81e279f2f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using RandomSampler\n",
      "Number of training samples: 54000\n",
      "Number of training batches: 211\n",
      "\n",
      "Starting 25-epoch training loop...\n",
      "Random seed: 6498985492641146865\n",
      "\n",
      "SGD epochs: 25 | Codistillation epochs: 0 | SWA epochs: 0\n",
      "DistributedDataParallel: False\n",
      "Stopping accuracy: None\n",
      "\n",
      "Train epoch: 1 | Metrics (epoch mean): cross_entropy=2.302523 <> acc=0.099705 | Batch (size 240): 211/211 (100%) | Total steps: 211\n",
      "Validation (batch mean) |  cross_entropy=2.302389 <> accuracy=0.102562 | Batch: 24/24 (100%)\n",
      "\n",
      "Train epoch: 2 | Metrics (epoch mean): cross_entropy=2.302165 <> acc=0.116089 | Batch (size 240): 211/211 (100%) | Total steps: 422\n",
      "Validation (batch mean) |  cross_entropy=2.301881 <> accuracy=0.191964 | Batch: 24/24 (100%)\n",
      "\n",
      "Train epoch: 3 | Metrics (epoch mean): cross_entropy=2.300951 <> acc=0.296127 | Batch (size 240): 211/211 (100%) | Total steps: 633\n",
      "Validation (batch mean) |  cross_entropy=2.299179 <> accuracy=0.390625 | Batch: 24/24 (100%)\n",
      "\n",
      "Train epoch: 4 | Metrics (epoch mean): cross_entropy=2.199784 <> acc=0.373819 | Batch (size 240): 211/211 (100%) | Total steps: 844\n",
      "Validation (batch mean) |  cross_entropy=2.022019 <> accuracy=0.435175 | Batch: 24/24 (100%)\n",
      "\n",
      "Train epoch: 5 | Metrics (epoch mean): cross_entropy=2.004379 <> acc=0.452355 | Batch (size 240): 211/211 (100%) | Total steps: 1055\n",
      "Validation (batch mean) |  cross_entropy=1.942495 <> accuracy=0.514486 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 6 | Metrics (epoch mean): cross_entropy=1.903483 <> acc=0.555480 | Batch (size 240): 211/211 (100%) | Total steps: 1266\n",
      "Validation (batch mean) |  cross_entropy=1.839858 <> accuracy=0.622675 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 7 | Metrics (epoch mean): cross_entropy=1.837167 <> acc=0.623229 | Batch (size 240): 211/211 (100%) | Total steps: 1477\n",
      "Validation (batch mean) |  cross_entropy=1.820294 <> accuracy=0.639834 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 8 | Metrics (epoch mean): cross_entropy=1.815683 <> acc=0.644742 | Batch (size 240): 211/211 (100%) | Total steps: 1688\n",
      "Validation (batch mean) |  cross_entropy=1.803944 <> accuracy=0.656320 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 9 | Metrics (epoch mean): cross_entropy=1.806642 <> acc=0.653600 | Batch (size 240): 211/211 (100%) | Total steps: 1899\n",
      "Validation (batch mean) |  cross_entropy=1.801842 <> accuracy=0.658157 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 10 | Metrics (epoch mean): cross_entropy=1.802579 <> acc=0.656680 | Batch (size 240): 211/211 (100%) | Total steps: 2110\n",
      "Validation (batch mean) |  cross_entropy=1.796494 <> accuracy=0.664342 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 11 | Metrics (epoch mean): cross_entropy=1.788792 <> acc=0.671311 | Batch (size 240): 211/211 (100%) | Total steps: 2321\n",
      "Validation (batch mean) |  cross_entropy=1.776172 <> accuracy=0.683733 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 12 | Metrics (epoch mean): cross_entropy=1.771461 <> acc=0.688337 | Batch (size 240): 211/211 (100%) | Total steps: 2532\n",
      "Validation (batch mean) |  cross_entropy=1.771596 <> accuracy=0.686314 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 13 | Metrics (epoch mean): cross_entropy=1.755997 <> acc=0.701741 | Batch (size 240): 211/211 (100%) | Total steps: 2743\n",
      "Validation (batch mean) |  cross_entropy=1.749181 <> accuracy=0.706148 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 14 | Metrics (epoch mean): cross_entropy=1.747759 <> acc=0.706276 | Batch (size 240): 211/211 (100%) | Total steps: 2954\n",
      "Validation (batch mean) |  cross_entropy=1.749627 <> accuracy=0.701381 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 15 | Metrics (epoch mean): cross_entropy=1.743508 <> acc=0.708833 | Batch (size 240): 211/211 (100%) | Total steps: 3165\n",
      "Validation (batch mean) |  cross_entropy=1.741036 <> accuracy=0.711519 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 16 | Metrics (epoch mean): cross_entropy=1.732880 <> acc=0.720243 | Batch (size 240): 211/211 (100%) | Total steps: 3376\n",
      "Validation (batch mean) |  cross_entropy=1.723140 <> accuracy=0.729469 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 17 | Metrics (epoch mean): cross_entropy=1.703058 <> acc=0.751122 | Batch (size 240): 211/211 (100%) | Total steps: 3587\n",
      "Validation (batch mean) |  cross_entropy=1.699874 <> accuracy=0.752674 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 18 | Metrics (epoch mean): cross_entropy=1.687058 <> acc=0.766116 | Batch (size 240): 211/211 (100%) | Total steps: 3798\n",
      "Validation (batch mean) |  cross_entropy=1.692677 <> accuracy=0.758743 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 19 | Metrics (epoch mean): cross_entropy=1.678383 <> acc=0.774057 | Batch (size 240): 211/211 (100%) | Total steps: 4009\n",
      "Validation (batch mean) |  cross_entropy=1.681771 <> accuracy=0.769531 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 20 | Metrics (epoch mean): cross_entropy=1.675042 <> acc=0.777310 | Batch (size 240): 211/211 (100%) | Total steps: 4220\n",
      "Validation (batch mean) |  cross_entropy=1.683543 <> accuracy=0.767090 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 21 | Metrics (epoch mean): cross_entropy=1.637569 <> acc=0.822119 | Batch (size 240): 211/211 (100%) | Total steps: 4431\n",
      "Validation (batch mean) |  cross_entropy=1.610600 <> accuracy=0.850260 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 22 | Metrics (epoch mean): cross_entropy=1.604228 <> acc=0.856781 | Batch (size 240): 211/211 (100%) | Total steps: 4642\n",
      "Validation (batch mean) |  cross_entropy=1.604541 <> accuracy=0.857817 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 23 | Metrics (epoch mean): cross_entropy=1.598403 <> acc=0.863370 | Batch (size 240): 211/211 (100%) | Total steps: 4853\n",
      "Validation (batch mean) |  cross_entropy=1.607551 <> accuracy=0.855608 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 24 | Metrics (epoch mean): cross_entropy=1.598267 <> acc=0.863608 | Batch (size 240): 211/211 (100%) | Total steps: 5064\n",
      "Validation (batch mean) |  cross_entropy=1.605890 <> accuracy=0.855887 | Batch: 24/24 (100%))\n",
      "\n",
      "Train epoch: 25 | Metrics (epoch mean): cross_entropy=1.589246 <> acc=0.871973 | Batch (size 240): 211/211 (100%) | Total steps: 5275\n",
      "Validation (batch mean) |  cross_entropy=1.592769 <> accuracy=0.868141 | Batch: 24/24 (100%))\n",
      "\n",
      "CPU times: user 3min 6s, sys: 29.9 s, total: 3min 36s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# whether to log training to Tensorboard\n",
    "log = False\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# optimizer\n",
    "lr0, momentum,  = 2**-8., 0.975\n",
    "\n",
    "# scheduler\n",
    "alpha, decay_epochs = 0.25, 15\n",
    "\n",
    "# training epochs\n",
    "epochs_sgd = 25\n",
    "\n",
    "# loaders\n",
    "train_loader, valid_loader = get_dataloaders(dataset=\"fashionmnist\",\n",
    "                                             batch_size=batch_size, \n",
    "                                             num_workers=4, \n",
    "                                             test=False,\n",
    "                                             pin_memory=cuda)\n",
    "\n",
    "# keep starting params consistent across runs\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# model\n",
    "simplecnn = SimpleCNN()\n",
    "\n",
    "# optimizer and scheduler\n",
    "optimizer = torch.optim.SGD(simplecnn.parameters(), \n",
    "                            lr=lr0, \n",
    "                            momentum=momentum, \n",
    "                            nesterov=False)\n",
    "\n",
    "\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(simplecnn, \n",
    "                  train_loader, \n",
    "                  valid_loader, \n",
    "                  F.cross_entropy, \n",
    "                  optimizer, \n",
    "                #   scheduler=scheduler, \n",
    "                  device=device,\n",
    "                  name='sgd',\n",
    "                  log=log)\n",
    "\n",
    "# begin training\n",
    "trainer(epochs_sgd=epochs_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4860c30a-0819-4f43-ab62-569868642966",
   "metadata": {},
   "source": [
    "### Validation accuracy by target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80c5db12-3390-43d6-810d-3889438c9bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 86%\n",
      "Accuracy for class: shirt/top is 85.9 %\n",
      "Accuracy for class: Trouser is 97.9 %\n",
      "Accuracy for class: Pullover is 76.2 %\n",
      "Accuracy for class: Dress is 82.1 %\n",
      "Accuracy for class: Coat  is 77.4 %\n",
      "Accuracy for class: Sandal is 95.8 %\n",
      "Accuracy for class: Shirt is 62.8 %\n",
      "Accuracy for class: Sneaker is 97.5 %\n",
      "Accuracy for class: Bag   is 97.6 %\n",
      "Accuracy for class: Ankle boot is 95.5 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Ankle boot</th>\n",
       "      <th>Bag</th>\n",
       "      <th>Coat</th>\n",
       "      <th>Dress</th>\n",
       "      <th>Pullover</th>\n",
       "      <th>Sandal</th>\n",
       "      <th>Shirt</th>\n",
       "      <th>Sneaker</th>\n",
       "      <th>Trouser</th>\n",
       "      <th>shirt/top</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ankle boot</th>\n",
       "      <td>591</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag</th>\n",
       "      <td>2</td>\n",
       "      <td>601</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coat</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>490</td>\n",
       "      <td>14</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dress</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>497</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pullover</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sandal</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>566</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shirt</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sneaker</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trouser</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shirt/top</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       Ankle boot  Bag  Coat  Dress  Pullover  Sandal  Shirt  Sneaker  \\\n",
       "row_0                                                                        \n",
       "Ankle boot         591    0     0      0         0       6      0       22   \n",
       "Bag                  2  601     5      0         3       0      4        0   \n",
       "Coat                 0    4   490     14        66       0     55        0   \n",
       "Dress                0    1    24    497        11       0     17        0   \n",
       "Pullover             0   12    73      2       459       1     52        0   \n",
       "Sandal               5    3     0      0         0     566      0       17   \n",
       "Shirt                0    5    40      8        67       0    355        0   \n",
       "Sneaker              9    1     0      0         0       4      0      541   \n",
       "Trouser              0    2     2      6         1       0      0        0   \n",
       "shirt/top            0    8     0     11        18       1     51        0   \n",
       "\n",
       "col_0       Trouser  shirt/top  \n",
       "row_0                           \n",
       "Ankle boot        0          0  \n",
       "Bag               0          1  \n",
       "Coat              3          1  \n",
       "Dress            18         37  \n",
       "Pullover          0          3  \n",
       "Sandal            0          0  \n",
       "Shirt             3         87  \n",
       "Sneaker           0          0  \n",
       "Trouser         572          1  \n",
       "shirt/top         0        541  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplecnn.to(device)\n",
    "\n",
    "classes = np.array([\n",
    "    'shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'])\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "labels = []\n",
    "preds = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for data in valid_loader:\n",
    "        images, target = data\n",
    "        labels.append(target.numpy())\n",
    "        outputs = simplecnn(images.to(device)).cpu()\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        preds.append(predictions)\n",
    "        total += target.size(0)\n",
    "        correct += (predictions == target).sum().item()\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(target, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "print(f'Validation accuracy: {100 * correct // total}%')\n",
    "            \n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "\n",
    "labels = pd.Series(np.hstack(labels).astype(int), name=\"Labels\")\n",
    "preds = pd.Series(np.hstack(preds).astype(int), name=\"Preds\")\n",
    "df_confusion = pd.crosstab(classes[labels], classes[preds])\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1060cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78b017421d80603e4213373f14806aa69ee9244ff1af847ead1b1014e100d80b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
