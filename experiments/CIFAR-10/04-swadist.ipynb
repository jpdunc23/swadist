{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "seed: 2246400\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "from swadist.utils import spawn_fn\n",
    "\n",
    "# mp.spawn may throw an error without this\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print('Using cuda')\n",
    "else:\n",
    "    print('Using cpu')\n",
    "\n",
    "seed = int((datetime.date.today() - datetime.date(2022, 4, 11)).total_seconds())\n",
    "print(f'seed: {seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of model replicas\n",
    "world_size = 2\n",
    "\n",
    "dataloader_kwargs = {\n",
    "    'dataset': 'cifar10',\n",
    "    'batch_size': 256 // world_size,\n",
    "    'num_workers': 2,\n",
    "}\n",
    "\n",
    "model_kwargs = {\n",
    "    'n_classes': 10,\n",
    "    'in_kernel_size': 3,\n",
    "    'stack_sizes': [1, 1, 1],\n",
    "    'batch_norm': False,\n",
    "}\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'lr': 2**-5.,\n",
    "    'momentum': 0.975,\n",
    "    'nesterov': True,\n",
    "}\n",
    "\n",
    "trainer_kwargs = {\n",
    "    # whether to log training to Tensorboard\n",
    "    'log': False,\n",
    "    'log_dir': './runs-notebooks',\n",
    "}\n",
    "\n",
    "train_kwargs = {\n",
    "    'epochs_sgd': 5,\n",
    "    'epochs_codist': 0,\n",
    "    'epochs_swa': 10,\n",
    "    'swadist': True,\n",
    "    'codist_kwargs': {\n",
    "        'sync_freq': 50,\n",
    "        'transform': 'softmax',\n",
    "        'debug': False,\n",
    "    },\n",
    "    'swadist_kwargs': {\n",
    "        'max_averaged': 3,\n",
    "        'sync_freq': 50,\n",
    "        'transform': 'softmax',\n",
    "        'debug': False,\n",
    "    },\n",
    "    # 'validations_per_epoch': 4,\n",
    "    'save': False,\n",
    "    'save_dir': './_state_dicts',\n",
    "    # 'stopping_acc': 0.7,\n",
    "}\n",
    "\n",
    "scheduler_kwargs = {\n",
    "    'alpha': 0.25,\n",
    "    'decay_epochs': 15,\n",
    "}\n",
    "\n",
    "# swa_scheduler_kwargs = {\n",
    "#     'swa_lr':  optimizer_kwargs['lr'] / 10, \n",
    "#     'anneal_strategy': 'cos',\n",
    "#     'anneal_epochs': 3,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0: joined process group on device cuda with backend nccl\n",
      "Rank 0: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 1/2 starting 15-epoch training loop...\n",
      "SGD epochs: 5 | Codistillation epochs: 0 | SWADist epochs: 10\n",
      "DistributedDataParallel: False\n",
      "Stopping accuracy: None\n",
      "\n",
      "Rank 1: joined process group on device cuda with backend nccl\n",
      "Rank 1: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 2/2 starting 15-epoch training loop...\n",
      "Train epoch: 1 | Metrics (epoch mean): cross_entropy=1.923153 <> acc=0.273303 | Batch (size 100): 176/176 (100%) | Total steps: 176\n",
      "Rank 0 | Validation mean |  cross_entropy=1.703109 <> accuracy=0.381055 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.687452 <> accuracy=0.388672 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 2 | Metrics (epoch mean): cross_entropy=1.536499 <> acc=0.438496 | Batch (size 100): 176/176 (100%) | Total steps: 352\n",
      "Rank 0 | Validation mean |  cross_entropy=1.401950 <> accuracy=0.500391 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.409843 <> accuracy=0.480859 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 3 | Metrics (epoch mean): cross_entropy=1.318048 <> acc=0.523040 | Batch (size 100): 176/176 (100%) | Total steps: 528\n",
      "Rank 0 | Validation mean |  cross_entropy=1.272105 <> accuracy=0.547266 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.335315 <> accuracy=0.528906 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 4 | Metrics (epoch mean): cross_entropy=1.184684 <> acc=0.578935 | Batch (size 100): 176/176 (100%) | Total steps: 704\n",
      "Rank 0 | Validation mean |  cross_entropy=1.162086 <> accuracy=0.593555 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.150105 <> accuracy=0.589453 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 5 | Metrics (epoch mean): cross_entropy=1.090007 <> acc=0.612594 | Batch (size 100): 176/176 (100%) | Total steps: 880\n",
      "Rank 0 | Validation mean |  cross_entropy=1.089447 <> accuracy=0.624609 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.109997 <> accuracy=0.620508 | Batch: 40/40 (100%)\n",
      "\n",
      "Starting SWADist phase...\n",
      "\n",
      "Train epoch: 6 | Metrics (epoch mean): cross_entropy=0.991579 <> acc=0.648540 <> swadist_loss=1.326180 | Batch (size 100): 176/176 (100%) | Total steps: 1056\n",
      "Rank 0 | Validation mean |  cross_entropy=1.009526 <> accuracy=0.653906 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.000575 <> accuracy=0.652148 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 7 | Metrics (epoch mean): cross_entropy=0.901923 <> acc=0.679638 <> swadist_loss=1.179621 | Batch (size 100): 176/176 (100%) | Total steps: 1232\n",
      "Rank 0 | Validation mean |  cross_entropy=0.965542 <> accuracy=0.671289 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.958792 <> accuracy=0.668164 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 8 | Metrics (epoch mean): cross_entropy=0.852849 <> acc=0.699975 <> swadist_loss=1.215708 | Batch (size 100): 176/176 (100%) | Total steps: 1408\n",
      "Rank 0 | Validation mean |  cross_entropy=0.915087 <> accuracy=0.696875 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.917432 <> accuracy=0.679883 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 9 | Metrics (epoch mean): cross_entropy=0.815739 <> acc=0.714622 <> swadist_loss=1.153801 | Batch (size 100): 176/176 (100%) | Total steps: 1584\n",
      "Rank 0 | Validation mean |  cross_entropy=0.883991 <> accuracy=0.705078 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.889808 <> accuracy=0.692969 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 10 | Metrics (epoch mean): cross_entropy=0.790316 <> acc=0.722841 <> swadist_loss=1.115716 | Batch (size 100): 176/176 (100%) | Total steps: 1760\n",
      "Rank 0 | Validation mean |  cross_entropy=0.859475 <> accuracy=0.712109 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.865123 <> accuracy=0.703125 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 11 | Metrics (epoch mean): cross_entropy=0.746821 <> acc=0.739714 <> swadist_loss=1.073434 | Batch (size 100): 176/176 (100%) | Total steps: 1936\n",
      "Rank 0 | Validation mean |  cross_entropy=0.843501 <> accuracy=0.711719 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.847908 <> accuracy=0.713281 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 12 | Metrics (epoch mean): cross_entropy=0.712348 <> acc=0.751413 <> swadist_loss=1.056849 | Batch (size 100): 176/176 (100%) | Total steps: 2112\n",
      "Rank 0 | Validation mean |  cross_entropy=0.830239 <> accuracy=0.713477 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.836883 <> accuracy=0.717578 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 13 | Metrics (epoch mean): cross_entropy=0.684135 <> acc=0.763507 <> swadist_loss=1.045410 | Batch (size 100): 176/176 (100%) | Total steps: 2288\n",
      "Rank 0 | Validation mean |  cross_entropy=0.815358 <> accuracy=0.720508 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.824148 <> accuracy=0.721094 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 14 | Metrics (epoch mean): cross_entropy=0.638328 <> acc=0.778762 <> swadist_loss=1.003602 | Batch (size 100): 176/176 (100%) | Total steps: 2464\n",
      "Rank 0 | Validation mean |  cross_entropy=0.815914 <> accuracy=0.728320 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.813319 <> accuracy=0.725391 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 15 | Metrics (epoch mean): cross_entropy=0.612610 <> acc=0.788707 <> swadist_loss=0.988771 | Batch (size 100): 176/176 (100%) | Total steps: 2640\n",
      "Rank 0 | Validation mean |  cross_entropy=0.813216 <> accuracy=0.728906 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.813327 <> accuracy=0.726562 | Batch: 40/40 (100%)\n",
      "\n",
      "CPU times: user 52 ms, sys: 18.6 ms, total: 70.7 ms\n",
      "Wall time: 4min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer_kwargs['name'] = 'swadist-v2-data-parallel'\n",
    "\n",
    "dataloader_kwargs['data_parallel'] = True\n",
    "dataloader_kwargs['split_training'] = False\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs,\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 [conda:torch]",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
