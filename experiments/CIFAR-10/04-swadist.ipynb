{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "seed: 2246400\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "from swadist.utils import spawn_fn\n",
    "\n",
    "# mp.spawn may throw an error without this\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print('Using cuda')\n",
    "else:\n",
    "    print('Using cpu')\n",
    "\n",
    "seed = int((datetime.date.today() - datetime.date(2022, 4, 11)).total_seconds())\n",
    "print(f'seed: {seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of model replicas\n",
    "world_size = 2\n",
    "\n",
    "dataloader_kwargs = {\n",
    "    'dataset': 'cifar10',\n",
    "    'batch_size': 256 // world_size,\n",
    "    'num_workers': 2,\n",
    "}\n",
    "\n",
    "model_kwargs = {\n",
    "    'n_classes': 10,\n",
    "    'in_kernel_size': 3,\n",
    "    'stack_sizes': [1, 1, 1],\n",
    "    'batch_norm': False,\n",
    "}\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'lr': 2**-5.,\n",
    "    'momentum': 0.975,\n",
    "    'nesterov': True,\n",
    "}\n",
    "\n",
    "trainer_kwargs = {\n",
    "    # whether to log training to Tensorboard\n",
    "    'log': False,\n",
    "    'log_dir': './runs-notebooks',\n",
    "}\n",
    "\n",
    "train_kwargs = {\n",
    "    'epochs_sgd': 0,\n",
    "    'epochs_codist': 0,\n",
    "    'epochs_swa': 15,\n",
    "    'swadist': True,\n",
    "    'codist_kwargs': {\n",
    "        'sync_freq': 50,\n",
    "        'transform': 'softmax',\n",
    "        'debug': False,\n",
    "    },\n",
    "    'swadist_kwargs': {\n",
    "        'max_averaged': 3,\n",
    "        'sync_freq': 50,\n",
    "        'transform': 'softmax',\n",
    "        'debug': False,\n",
    "    },\n",
    "    # 'validations_per_epoch': 4,\n",
    "    'save': False,\n",
    "    'save_dir': './_state_dicts',\n",
    "    # 'stopping_acc': 0.7,\n",
    "}\n",
    "\n",
    "scheduler_kwargs = {\n",
    "    'alpha': 0.25,\n",
    "    'decay_epochs': 15,\n",
    "}\n",
    "\n",
    "# swa_scheduler_kwargs = {\n",
    "#     'swa_lr':  optimizer_kwargs['lr'] / 10, \n",
    "#     'anneal_strategy': 'cos',\n",
    "#     'anneal_epochs': 3,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0: joined process group on device cuda with backend nccl\n",
      "Rank 0: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 1/2 starting 15-epoch training loop...\n",
      "SGD epochs: 0 | Codistillation epochs: 0 | SWADist epochs: 15\n",
      "DistributedDataParallel: False\n",
      "Stopping accuracy: None\n",
      "\n",
      "Starting SWADist phase...\n",
      "\n",
      "Rank 1: joined process group on device cuda with backend nccl\n",
      "Rank 1: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 2/2 starting 15-epoch training loop...\n",
      "Train epoch: 1 | Metrics (epoch mean): cross_entropy=1.960304 <> acc=0.260868 <> swadist_loss=2.173560 | Batch (size 100): 176/176 (100%) | Total steps: 176\n",
      "Rank 0 | Validation mean |  cross_entropy=2.014968 <> accuracy=0.277734 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=2.083179 <> accuracy=0.281250 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 2 | Metrics (epoch mean): cross_entropy=1.577718 <> acc=0.424457 <> swadist_loss=1.911338 | Batch (size 100): 176/176 (100%) | Total steps: 352\n",
      "Rank 0 | Validation mean |  cross_entropy=1.836105 <> accuracy=0.365820 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.911373 <> accuracy=0.338672 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 3 | Metrics (epoch mean): cross_entropy=1.361573 <> acc=0.511926 <> swadist_loss=1.642181 | Batch (size 100): 176/176 (100%) | Total steps: 528\n",
      "Rank 0 | Validation mean |  cross_entropy=1.475288 <> accuracy=0.474609 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.493348 <> accuracy=0.468359 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 4 | Metrics (epoch mean): cross_entropy=1.202770 <> acc=0.570678 <> swadist_loss=1.492126 | Batch (size 100): 176/176 (100%) | Total steps: 704\n",
      "Rank 0 | Validation mean |  cross_entropy=1.252968 <> accuracy=0.566797 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.299370 <> accuracy=0.544531 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 5 | Metrics (epoch mean): cross_entropy=1.113236 <> acc=0.603331 <> swadist_loss=1.401280 | Batch (size 100): 176/176 (100%) | Total steps: 880\n",
      "Rank 0 | Validation mean |  cross_entropy=1.138818 <> accuracy=0.600586 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.165938 <> accuracy=0.585352 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 6 | Metrics (epoch mean): cross_entropy=1.038319 <> acc=0.630964 <> swadist_loss=1.334189 | Batch (size 100): 176/176 (100%) | Total steps: 1056\n",
      "Rank 0 | Validation mean |  cross_entropy=1.051288 <> accuracy=0.631641 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.061831 <> accuracy=0.629102 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 7 | Metrics (epoch mean): cross_entropy=0.961031 <> acc=0.659105 <> swadist_loss=1.251063 | Batch (size 100): 176/176 (100%) | Total steps: 1232\n",
      "Rank 0 | Validation mean |  cross_entropy=0.988975 <> accuracy=0.650000 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.999213 <> accuracy=0.653906 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 8 | Metrics (epoch mean): cross_entropy=0.900988 <> acc=0.683533 <> swadist_loss=1.195178 | Batch (size 100): 176/176 (100%) | Total steps: 1408\n",
      "Rank 0 | Validation mean |  cross_entropy=0.941959 <> accuracy=0.669531 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.947984 <> accuracy=0.663281 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 9 | Metrics (epoch mean): cross_entropy=0.857221 <> acc=0.699574 <> swadist_loss=1.201586 | Batch (size 100): 176/176 (100%) | Total steps: 1584\n",
      "Rank 0 | Validation mean |  cross_entropy=0.898427 <> accuracy=0.691797 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.905679 <> accuracy=0.680859 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 10 | Metrics (epoch mean): cross_entropy=0.818081 <> acc=0.713741 <> swadist_loss=1.143037 | Batch (size 100): 176/176 (100%) | Total steps: 1760\n",
      "Rank 0 | Validation mean |  cross_entropy=0.873620 <> accuracy=0.703906 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.866432 <> accuracy=0.705078 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 11 | Metrics (epoch mean): cross_entropy=0.772998 <> acc=0.732347 <> swadist_loss=1.118308 | Batch (size 100): 176/176 (100%) | Total steps: 1936\n",
      "Rank 0 | Validation mean |  cross_entropy=0.833734 <> accuracy=0.720703 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.828243 <> accuracy=0.719922 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 12 | Metrics (epoch mean): cross_entropy=0.728230 <> acc=0.748801 <> swadist_loss=1.088635 | Batch (size 100): 176/176 (100%) | Total steps: 2112\n",
      "Rank 0 | Validation mean |  cross_entropy=0.809893 <> accuracy=0.725781 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.824460 <> accuracy=0.722461 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 13 | Metrics (epoch mean): cross_entropy=0.701017 <> acc=0.756818 <> swadist_loss=1.050319 | Batch (size 100): 176/176 (100%) | Total steps: 2288\n",
      "Rank 0 | Validation mean |  cross_entropy=0.802881 <> accuracy=0.725781 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.788395 <> accuracy=0.732813 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 14 | Metrics (epoch mean): cross_entropy=0.656358 <> acc=0.770245 <> swadist_loss=0.997371 | Batch (size 100): 176/176 (100%) | Total steps: 2464\n",
      "Rank 0 | Validation mean |  cross_entropy=0.809274 <> accuracy=0.725000 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.774234 <> accuracy=0.734375 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 15 | Metrics (epoch mean): cross_entropy=0.620792 <> acc=0.782404 <> swadist_loss=1.013111 | Batch (size 100): 176/176 (100%) | Total steps: 2640\n",
      "Rank 0 | Validation mean |  cross_entropy=0.795992 <> accuracy=0.728516 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.766633 <> accuracy=0.740820 | Batch: 40/40 (100%)\n",
      "\n",
      "CPU times: user 74.6 ms, sys: 12.1 ms, total: 86.7 ms\n",
      "Wall time: 5min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer_kwargs['name'] = 'swadist-v2-data-parallel'\n",
    "\n",
    "dataloader_kwargs['data_parallel'] = True\n",
    "dataloader_kwargs['split_training'] = False\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs,\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 [conda:torch]",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
