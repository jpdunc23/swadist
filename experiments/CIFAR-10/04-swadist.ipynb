{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "from swadist.utils import spawn_fn\n",
    "\n",
    "# mp.spawn may throw an error without this\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print('Using cuda')\n",
    "else:\n",
    "    print('Using cpu')\n",
    "\n",
    "seed = int((datetime.date.today() - datetime.date(2022, 4, 11)).total_seconds())\n",
    "print(f'seed: {seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of model replicas\n",
    "world_size = 2\n",
    "\n",
    "dataloader_kwargs = {\n",
    "    'dataset': 'cifar10',\n",
    "    'batch_size': 256 // world_size,\n",
    "    'num_workers': 2,\n",
    "}\n",
    "\n",
    "model_kwargs = {\n",
    "    'n_classes': 10,\n",
    "    'in_kernel_size': 3,\n",
    "    'stack_sizes': [1, 1, 1],\n",
    "    'batch_norm': False,\n",
    "}\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'lr': 2**-5.,\n",
    "    'momentum': 0.975,\n",
    "    'nesterov': True,\n",
    "}\n",
    "\n",
    "trainer_kwargs = {\n",
    "    # whether to log training to Tensorboard\n",
    "    'log': True,\n",
    "    'log_dir': './runs-notebooks',\n",
    "}\n",
    "\n",
    "train_kwargs = {\n",
    "    'epochs_sgd': 0,\n",
    "    'swadist': True,\n",
    "    'codist_kwargs': {\n",
    "        'sync_freq': 50,\n",
    "        'transform': 'softmax',\n",
    "        'debug': False,\n",
    "    },\n",
    "    'swadist_kwargs': {\n",
    "        'max_averaged': 3,\n",
    "        'sync_freq': 50,\n",
    "        'transform': 'softmax',\n",
    "        'debug': True,\n",
    "    },\n",
    "    'save': True,\n",
    "    'save_dir': './_state_dicts',\n",
    "    # 'stopping_acc': 0.7,\n",
    "}\n",
    "\n",
    "scheduler_kwargs = {\n",
    "    'alpha': 0.25,\n",
    "    'decay_epochs': 15,\n",
    "}\n",
    "\n",
    "# swa_scheduler_kwargs = {\n",
    "#     'swa_lr':  optimizer_kwargs['lr'] / 10, \n",
    "#     'anneal_strategy': 'cos',\n",
    "#     'anneal_epochs': 3,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer_kwargs['name'] = 'swadist-dp'\n",
    "\n",
    "dataloader_kwargs['data_parallel'] = True\n",
    "dataloader_kwargs['split_training'] = False\n",
    "\n",
    "train_kwargs['epochs_sgd'] = 0 # 5 # TODO\n",
    "train_kwargs['epochs_swa'] = 8\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs,\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer_kwargs['name'] = 'swadist-swa-replicas-dp'\n",
    "\n",
    "dataloader_kwargs['data_parallel'] = True\n",
    "dataloader_kwargs['split_training'] = False\n",
    "\n",
    "train_kwargs['epochs_sgd'] = 0\n",
    "train_kwargs['epochs_swa'] = 15\n",
    "train_kwargs['swadist_kwargs']['swa_replicas'] = True\n",
    "train_kwargs['stop_stall_n_epochs'] = 3\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs,\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer_kwargs['name'] = 'swadist-split'\n",
    "\n",
    "dataloader_kwargs['data_parallel'] = False\n",
    "dataloader_kwargs['split_training'] = True\n",
    "\n",
    "train_kwargs['epochs_sgd'] = 5\n",
    "train_kwargs['epochs_swa'] = 20\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs,\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer_kwargs['name'] = 'swadist-swa-replicas-split'\n",
    "\n",
    "dataloader_kwargs['data_parallel'] = False\n",
    "dataloader_kwargs['split_training'] = True\n",
    "\n",
    "train_kwargs['epochs_sgd'] = 5\n",
    "train_kwargs['epochs_swa'] = 20\n",
    "\n",
    "train_kwargs['swadist_kwargs']['swa_replicas'] = True\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs,\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer_kwargs['name'] = 'swadist-dp-no-sgd'\n",
    "\n",
    "dataloader_kwargs['data_parallel'] = True\n",
    "dataloader_kwargs['split_training'] = False\n",
    "\n",
    "train_kwargs['epochs_sgd'] = 0\n",
    "train_kwargs['epochs_swa'] = 25\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs,\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer_kwargs['name'] = 'swadist-swa-replicas-dp-no-sgd'\n",
    "\n",
    "dataloader_kwargs['data_parallel'] = True\n",
    "dataloader_kwargs['split_training'] = False\n",
    "\n",
    "train_kwargs['epochs_sgd'] = 0\n",
    "train_kwargs['epochs_swa'] = 25\n",
    "\n",
    "train_kwargs['swadist_kwargs']['swa_replicas'] = True\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs,\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer_kwargs['name'] = 'swadist-split-no-sgd'\n",
    "\n",
    "dataloader_kwargs['data_parallel'] = False\n",
    "dataloader_kwargs['split_training'] = True\n",
    "\n",
    "train_kwargs['epochs_sgd'] = 0\n",
    "train_kwargs['epochs_swa'] = 25\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs,\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer_kwargs['name'] = 'swadist-swa-replicas-split-no-sgd'\n",
    "\n",
    "dataloader_kwargs['data_parallel'] = False\n",
    "dataloader_kwargs['split_training'] = True\n",
    "\n",
    "train_kwargs['epochs_sgd'] = 0\n",
    "train_kwargs['epochs_swa'] = 25\n",
    "\n",
    "train_kwargs['swadist_kwargs']['swa_replicas'] = True\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs,\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer_kwargs['name'] = 'swadist-ablate-codist-dp'\n",
    "\n",
    "dataloader_kwargs['data_parallel'] = True\n",
    "dataloader_kwargs['split_training'] = False\n",
    "\n",
    "train_kwargs['epochs_sgd'] = 0\n",
    "train_kwargs['epochs_swa'] = 15\n",
    "train_kwargs['codist_kwargs']['sync_freq'] = 0\n",
    "train_kwargs['swadist_kwargs']['swa_replicas'] = False\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs,\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer_kwargs['name'] = 'swadist-swa-replicas-ablate-codist-dp'\n",
    "\n",
    "dataloader_kwargs['data_parallel'] = True\n",
    "dataloader_kwargs['split_training'] = False\n",
    "\n",
    "train_kwargs['epochs_sgd'] = 0\n",
    "train_kwargs['epochs_swa'] = 15\n",
    "train_kwargs['codist_kwargs']['sync_freq'] = 0\n",
    "train_kwargs['swadist_kwargs']['swa_replicas'] = True\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs,\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
