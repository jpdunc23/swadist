{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "seed: 2246400\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "from swadist.utils import spawn_fn\n",
    "\n",
    "# mp.spawn may throw an error without this\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print('Using cuda')\n",
    "else:\n",
    "    print('Using cpu')\n",
    "\n",
    "seed = int((datetime.date.today() - datetime.date(2022, 4, 11)).total_seconds())\n",
    "print(f'seed: {seed}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- **Common arguments**\n",
    "- **Asynchronous data-parallel SGD**\n",
    "- **Asynchronous SGD + Codistillation**\n",
    "- **Asynchronous SGD + Codistillation w/ data partitioning**\n",
    "- **Codistillation w/ data partioning only**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of model replicas\n",
    "world_size = 2\n",
    "\n",
    "dataloader_kwargs = {\n",
    "    'dataset': 'cifar10',\n",
    "    # size of training batches on each rank\n",
    "    'batch_size': 256 // world_size,\n",
    "    # cpu processes per rank for data loading\n",
    "    'num_workers': 2,\n",
    "}\n",
    "\n",
    "model_kwargs = {\n",
    "    'n_classes': 10,\n",
    "    'in_kernel_size': 3,\n",
    "    'stack_sizes': [1, 1, 1],\n",
    "    'batch_norm': False,\n",
    "}\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'lr': 2**-5.,\n",
    "    'momentum': 0.975,\n",
    "    'nesterov': True,\n",
    "}\n",
    "\n",
    "trainer_kwargs = {\n",
    "    # whether to log training to Tensorboard\n",
    "    'log': False,\n",
    "}\n",
    "\n",
    "train_kwargs = {}\n",
    "\n",
    "scheduler_kwargs = {\n",
    "    'alpha': 0.25,\n",
    "    'decay_epochs': 15,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous data-parallel SGD\n",
    "\n",
    "Run asynchronous SGD in parallel with distributed sampling for 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: joined process group on device cuda with backend nccl\n",
      "Rank 1: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 2/2 starting 15-epoch training loop...\n",
      "Rank 0: joined process group on device cuda with backend nccl\n",
      "Rank 0: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 1/2 starting 15-epoch training loop...\n",
      "SGD epochs: 15 | Codistillation epochs: 0 | SWA epochs: 0\n",
      "DistributedDataParallel: False\n",
      "Stopping accuracy: None\n",
      "\n",
      "Train epoch: 1 | Metrics (epoch mean): cross_entropy=1.924371 <> acc=0.272630 | Batch (size 100): 176/176 (100%) | Total steps: 176\n",
      "Rank 0 | Validation mean |  cross_entropy=1.701141 <> accuracy=0.379687 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.723494 <> accuracy=0.362500 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 2 | Metrics (epoch mean): cross_entropy=1.537804 <> acc=0.439588 | Batch (size 100): 176/176 (100%) | Total steps: 352\n",
      "Rank 0 | Validation mean |  cross_entropy=1.399429 <> accuracy=0.488672 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.468415 <> accuracy=0.462500 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 3 | Metrics (epoch mean): cross_entropy=1.318572 <> acc=0.522743 | Batch (size 100): 176/176 (100%) | Total steps: 528\n",
      "Rank 0 | Validation mean |  cross_entropy=1.257426 <> accuracy=0.559375 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.363838 <> accuracy=0.517578 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 4 | Metrics (epoch mean): cross_entropy=1.183583 <> acc=0.575909 | Batch (size 100): 176/176 (100%) | Total steps: 704\n",
      "Rank 0 | Validation mean |  cross_entropy=1.166017 <> accuracy=0.597461 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.186493 <> accuracy=0.584766 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 5 | Metrics (epoch mean): cross_entropy=1.080869 <> acc=0.617141 | Batch (size 100): 176/176 (100%) | Total steps: 880\n",
      "Rank 0 | Validation mean |  cross_entropy=1.069392 <> accuracy=0.633594 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.086382 <> accuracy=0.627148 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 6 | Metrics (epoch mean): cross_entropy=1.007772 <> acc=0.645236 | Batch (size 100): 176/176 (100%) | Total steps: 1056\n",
      "Rank 0 | Validation mean |  cross_entropy=1.024327 <> accuracy=0.645312 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.059339 <> accuracy=0.636914 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 7 | Metrics (epoch mean): cross_entropy=0.935934 <> acc=0.669189 | Batch (size 100): 176/176 (100%) | Total steps: 1232\n",
      "Rank 0 | Validation mean |  cross_entropy=0.990442 <> accuracy=0.671094 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.004405 <> accuracy=0.658203 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 8 | Metrics (epoch mean): cross_entropy=0.881416 <> acc=0.689284 | Batch (size 100): 176/176 (100%) | Total steps: 1408\n",
      "Rank 0 | Validation mean |  cross_entropy=0.928756 <> accuracy=0.684570 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.954720 <> accuracy=0.663672 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 9 | Metrics (epoch mean): cross_entropy=0.824639 <> acc=0.712072 | Batch (size 100): 176/176 (100%) | Total steps: 1584\n",
      "Rank 0 | Validation mean |  cross_entropy=0.900001 <> accuracy=0.694531 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.914199 <> accuracy=0.682031 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 10 | Metrics (epoch mean): cross_entropy=0.796202 <> acc=0.722582 | Batch (size 100): 176/176 (100%) | Total steps: 1760\n",
      "Rank 0 | Validation mean |  cross_entropy=0.886631 <> accuracy=0.704297 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.905572 <> accuracy=0.689648 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 11 | Metrics (epoch mean): cross_entropy=0.747724 <> acc=0.737640 | Batch (size 100): 176/176 (100%) | Total steps: 1936\n",
      "Rank 0 | Validation mean |  cross_entropy=0.860165 <> accuracy=0.701367 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.856031 <> accuracy=0.706836 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 12 | Metrics (epoch mean): cross_entropy=0.705191 <> acc=0.755453 | Batch (size 100): 176/176 (100%) | Total steps: 2112\n",
      "Rank 0 | Validation mean |  cross_entropy=0.865845 <> accuracy=0.712500 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.882185 <> accuracy=0.705664 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 13 | Metrics (epoch mean): cross_entropy=0.662666 <> acc=0.767287 | Batch (size 100): 176/176 (100%) | Total steps: 2288\n",
      "Rank 0 | Validation mean |  cross_entropy=0.822058 <> accuracy=0.726562 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.805801 <> accuracy=0.722266 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 14 | Metrics (epoch mean): cross_entropy=0.605061 <> acc=0.791490 | Batch (size 100): 176/176 (100%) | Total steps: 2464\n",
      "Rank 0 | Validation mean |  cross_entropy=0.815040 <> accuracy=0.729883 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.811487 <> accuracy=0.728320 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 15 | Metrics (epoch mean): cross_entropy=0.574005 <> acc=0.800964 | Batch (size 100): 176/176 (100%) | Total steps: 2640\n",
      "Rank 0 | Validation mean |  cross_entropy=0.829671 <> accuracy=0.725391 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.801157 <> accuracy=0.739453 | Batch: 40/40 (100%)\n",
      "\n",
      "CPU times: user 62.4 ms, sys: 13.9 ms, total: 76.3 ms\n",
      "Wall time: 3min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer_kwargs['name'] = 'async-sgd'\n",
    "\n",
    "# when true, uses DistributedSampler\n",
    "dataloader_kwargs['data_parallel'] = True\n",
    "\n",
    "train_kwargs['epochs_sgd'] = 15\n",
    "train_kwargs['epochs_codist'] = 0\n",
    "train_kwargs['epochs_swa'] = 0\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs\n",
    "        seed, # seed on rank i = seed + i\n",
    "        False) # ddp=False, don't use DistributedDataParallel\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous SGD + Codistillation\n",
    "\n",
    "Switch to codistillation after 5 epochs of asynchronous SGD and train for 15 epochs total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: joined process group on device cuda with backend nccl\n",
      "Rank 1: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 2/2 starting 15-epoch training loop...\n",
      "Rank 0: joined process group on device cuda with backend nccl\n",
      "Rank 0: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 1/2 starting 15-epoch training loop...\n",
      "SGD epochs: 5 | Codistillation epochs: 10 | SWA epochs: 0\n",
      "DistributedDataParallel: False\n",
      "Stopping accuracy: None\n",
      "\n",
      "Train epoch: 1 | Metrics (epoch mean): cross_entropy=1.923765 <> acc=0.273049 | Batch (size 100): 176/176 (100%) | Total steps: 176\n",
      "Rank 0 | Validation mean |  cross_entropy=1.696760 <> accuracy=0.376367 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.742668 <> accuracy=0.344727 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 2 | Metrics (epoch mean): cross_entropy=1.532894 <> acc=0.440190 | Batch (size 100): 176/176 (100%) | Total steps: 352\n",
      "Rank 0 | Validation mean |  cross_entropy=1.421066 <> accuracy=0.490430 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.503475 <> accuracy=0.449414 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 3 | Metrics (epoch mean): cross_entropy=1.319034 <> acc=0.524487 | Batch (size 100): 176/176 (100%) | Total steps: 528\n",
      "Rank 0 | Validation mean |  cross_entropy=1.263922 <> accuracy=0.547852 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.371201 <> accuracy=0.510547 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 4 | Metrics (epoch mean): cross_entropy=1.185000 <> acc=0.578276 | Batch (size 100): 176/176 (100%) | Total steps: 704\n",
      "Rank 0 | Validation mean |  cross_entropy=1.162994 <> accuracy=0.583789 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.248520 <> accuracy=0.550586 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 5 | Metrics (epoch mean): cross_entropy=1.082149 <> acc=0.615955 | Batch (size 100): 176/176 (100%) | Total steps: 880\n",
      "Rank 0 | Validation mean |  cross_entropy=1.097335 <> accuracy=0.628320 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.131448 <> accuracy=0.599219 | Batch: 40/40 (100%)\n",
      "\n",
      "Starting codistillation phase...\n",
      "\n",
      "Train epoch: 6 | Metrics (epoch mean): cross_entropy=1.015200 <> acc=0.647470 <> codist_loss=1.382854 | Batch (size 100): 176/176 (100%) | Total steps: 1056\n",
      "Rank 0 | Validation mean |  cross_entropy=1.022217 <> accuracy=0.654883 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.058599 <> accuracy=0.635547 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 7 | Metrics (epoch mean): cross_entropy=0.927976 <> acc=0.678446 <> codist_loss=1.298942 | Batch (size 100): 176/176 (100%) | Total steps: 1232\n",
      "Rank 0 | Validation mean |  cross_entropy=0.966373 <> accuracy=0.676953 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.010739 <> accuracy=0.653906 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 8 | Metrics (epoch mean): cross_entropy=0.873095 <> acc=0.697548 <> codist_loss=1.228527 | Batch (size 100): 176/176 (100%) | Total steps: 1408\n",
      "Rank 0 | Validation mean |  cross_entropy=0.938910 <> accuracy=0.682031 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.977137 <> accuracy=0.665430 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 9 | Metrics (epoch mean): cross_entropy=0.842581 <> acc=0.713017 <> codist_loss=1.179096 | Batch (size 100): 176/176 (100%) | Total steps: 1584\n",
      "Rank 0 | Validation mean |  cross_entropy=0.901467 <> accuracy=0.690625 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.951348 <> accuracy=0.674414 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 10 | Metrics (epoch mean): cross_entropy=0.832179 <> acc=0.716126 <> codist_loss=1.152918 | Batch (size 100): 176/176 (100%) | Total steps: 1760\n",
      "Rank 0 | Validation mean |  cross_entropy=0.890161 <> accuracy=0.700586 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.941231 <> accuracy=0.674609 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 11 | Metrics (epoch mean): cross_entropy=0.793944 <> acc=0.727241 <> codist_loss=1.129708 | Batch (size 100): 176/176 (100%) | Total steps: 1936\n",
      "Rank 0 | Validation mean |  cross_entropy=0.875089 <> accuracy=0.705664 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.914137 <> accuracy=0.690039 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 12 | Metrics (epoch mean): cross_entropy=0.763682 <> acc=0.741799 <> codist_loss=1.098994 | Batch (size 100): 176/176 (100%) | Total steps: 2112\n",
      "Rank 0 | Validation mean |  cross_entropy=0.843883 <> accuracy=0.716797 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.870520 <> accuracy=0.706445 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 13 | Metrics (epoch mean): cross_entropy=0.739123 <> acc=0.749290 <> codist_loss=1.074303 | Batch (size 100): 176/176 (100%) | Total steps: 2288\n",
      "Rank 0 | Validation mean |  cross_entropy=0.825388 <> accuracy=0.719922 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.867162 <> accuracy=0.705078 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 14 | Metrics (epoch mean): cross_entropy=0.703367 <> acc=0.767976 <> codist_loss=1.041089 | Batch (size 100): 176/176 (100%) | Total steps: 2464\n",
      "Rank 0 | Validation mean |  cross_entropy=0.821543 <> accuracy=0.717188 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.855377 <> accuracy=0.709961 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 15 | Metrics (epoch mean): cross_entropy=0.684970 <> acc=0.769812 <> codist_loss=1.011650 | Batch (size 100): 176/176 (100%) | Total steps: 2640\n",
      "Rank 0 | Validation mean |  cross_entropy=0.812784 <> accuracy=0.729492 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.856073 <> accuracy=0.709180 | Batch: 40/40 (100%)\n",
      "\n",
      "CPU times: user 58.9 ms, sys: 8.2 ms, total: 67.1 ms\n",
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "trainer_kwargs['name'] = 'codist'\n",
    "\n",
    "dataloader_kwargs['data_parallel'] = True\n",
    "    \n",
    "train_kwargs['epochs_sgd'] = 5\n",
    "train_kwargs['epochs_codist'] = 10\n",
    "train_kwargs['codist_kwargs'] = {\n",
    "    # how many steps before re-syncing stale replicas\n",
    "    'sync_freq': 50,\n",
    "    # transform to apply to mean replica output\n",
    "    'transform': 'softmax',\n",
    "    # when True, prints gather and update param steps\n",
    "    'debug': False,\n",
    "}\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous SGD + Codistillation w/ data partitioning\n",
    "\n",
    "As before, but this time we train each model replica on disjoint partitions of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0: joined process group on device cuda with backend nccl\n",
      "Rank 0: torch.manual_seed(2246400)\n",
      "Using SubsetRandomSampler with samples 0 to 22499\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 1/2 starting 15-epoch training loop...\n",
      "SGD epochs: 5 | Codistillation epochs: 10 | SWA epochs: 0\n",
      "DistributedDataParallel: False\n",
      "Stopping accuracy: None\n",
      "\n",
      "Rank 1: joined process group on device cuda with backend nccl\n",
      "Rank 1: torch.manual_seed(2246400)\n",
      "Using SubsetRandomSampler with samples 22500 to 44999\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 2/2 starting 15-epoch training loop...\n",
      "Train epoch: 1 | Metrics (epoch mean): cross_entropy=1.963035 <> acc=0.259380 | Batch (size 100): 176/176 (100%) | Total steps: 176\n",
      "Rank 0 | Validation mean |  cross_entropy=1.720386 <> accuracy=0.350391 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.665326 <> accuracy=0.394141 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 2 | Metrics (epoch mean): cross_entropy=1.576743 <> acc=0.422187 | Batch (size 100): 176/176 (100%) | Total steps: 352\n",
      "Rank 0 | Validation mean |  cross_entropy=1.483631 <> accuracy=0.460938 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.391002 <> accuracy=0.492188 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 3 | Metrics (epoch mean): cross_entropy=1.348081 <> acc=0.512422 | Batch (size 100): 176/176 (100%) | Total steps: 528\n",
      "Rank 0 | Validation mean |  cross_entropy=1.266530 <> accuracy=0.558398 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.220093 <> accuracy=0.570703 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 4 | Metrics (epoch mean): cross_entropy=1.197595 <> acc=0.571662 | Batch (size 100): 176/176 (100%) | Total steps: 704\n",
      "Rank 0 | Validation mean |  cross_entropy=1.232491 <> accuracy=0.574219 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.132013 <> accuracy=0.613477 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 5 | Metrics (epoch mean): cross_entropy=1.080787 <> acc=0.613121 | Batch (size 100): 176/176 (100%) | Total steps: 880\n",
      "Rank 0 | Validation mean |  cross_entropy=1.120598 <> accuracy=0.609766 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.109752 <> accuracy=0.611914 | Batch: 40/40 (100%)\n",
      "\n",
      "Starting codistillation phase...\n",
      "\n",
      "Train epoch: 6 | Metrics (epoch mean): cross_entropy=0.983663 <> acc=0.656096 <> codist_loss=1.368946 | Batch (size 100): 176/176 (100%) | Total steps: 1056\n",
      "Rank 0 | Validation mean |  cross_entropy=1.039936 <> accuracy=0.645703 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.008451 <> accuracy=0.657031 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 7 | Metrics (epoch mean): cross_entropy=0.888544 <> acc=0.694553 <> codist_loss=1.291005 | Batch (size 100): 176/176 (100%) | Total steps: 1232\n",
      "Rank 0 | Validation mean |  cross_entropy=0.981454 <> accuracy=0.666992 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.961623 <> accuracy=0.676758 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 8 | Metrics (epoch mean): cross_entropy=0.830271 <> acc=0.716445 <> codist_loss=1.209273 | Batch (size 100): 176/176 (100%) | Total steps: 1408\n",
      "Rank 0 | Validation mean |  cross_entropy=0.962095 <> accuracy=0.675781 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.945166 <> accuracy=0.679492 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 9 | Metrics (epoch mean): cross_entropy=0.783540 <> acc=0.735124 <> codist_loss=1.178159 | Batch (size 100): 176/176 (100%) | Total steps: 1584\n",
      "Rank 0 | Validation mean |  cross_entropy=0.948585 <> accuracy=0.681641 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.937075 <> accuracy=0.676172 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 10 | Metrics (epoch mean): cross_entropy=0.746620 <> acc=0.750012 <> codist_loss=1.160148 | Batch (size 100): 176/176 (100%) | Total steps: 1760\n",
      "Rank 0 | Validation mean |  cross_entropy=0.945174 <> accuracy=0.684375 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.922235 <> accuracy=0.686719 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 11 | Metrics (epoch mean): cross_entropy=0.709645 <> acc=0.759853 <> codist_loss=1.121015 | Batch (size 100): 176/176 (100%) | Total steps: 1936\n",
      "Rank 0 | Validation mean |  cross_entropy=0.925204 <> accuracy=0.688477 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.901402 <> accuracy=0.692969 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 12 | Metrics (epoch mean): cross_entropy=0.667702 <> acc=0.778390 <> codist_loss=1.096640 | Batch (size 100): 176/176 (100%) | Total steps: 2112\n",
      "Rank 0 | Validation mean |  cross_entropy=0.915962 <> accuracy=0.692969 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.889340 <> accuracy=0.699219 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 13 | Metrics (epoch mean): cross_entropy=0.633465 <> acc=0.792493 <> codist_loss=1.083216 | Batch (size 100): 176/176 (100%) | Total steps: 2288\n",
      "Rank 0 | Validation mean |  cross_entropy=0.914301 <> accuracy=0.691992 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.892083 <> accuracy=0.696875 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 14 | Metrics (epoch mean): cross_entropy=0.601368 <> acc=0.807115 <> codist_loss=1.073157 | Batch (size 100): 176/176 (100%) | Total steps: 2464\n",
      "Rank 0 | Validation mean |  cross_entropy=0.902649 <> accuracy=0.700195 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.867686 <> accuracy=0.701758 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 15 | Metrics (epoch mean): cross_entropy=0.570361 <> acc=0.819391 <> codist_loss=1.055166 | Batch (size 100): 176/176 (100%) | Total steps: 2640\n",
      "Rank 0 | Validation mean |  cross_entropy=0.904097 <> accuracy=0.697070 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.871332 <> accuracy=0.708398 | Batch: 40/40 (100%)\n",
      "\n",
      "CPU times: user 52 ms, sys: 9.42 ms, total: 61.4 ms\n",
      "Wall time: 3min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "trainer_kwargs['name'] = 'codist-split'\n",
    "\n",
    "# when True, restrict each rank to half of the data\n",
    "dataloader_kwargs['split_training'] = True\n",
    "dataloader_kwargs['data_parallel'] = False\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codistillation w/o data partitioning only\n",
    "\n",
    "Now run data-parallel codistillation for all 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: joined process group on device cuda with backend nccl\n",
      "Rank 1: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 2/2 starting 15-epoch training loop...\n",
      "Rank 0: joined process group on device cuda with backend nccl\n",
      "Rank 0: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 1/2 starting 15-epoch training loop...\n",
      "SGD epochs: 0 | Codistillation epochs: 15 | SWA epochs: 0\n",
      "DistributedDataParallel: False\n",
      "Stopping accuracy: None\n",
      "\n",
      "Starting codistillation phase...\n",
      "\n",
      "Train epoch: 1 | Metrics (epoch mean): cross_entropy=1.992084 <> acc=0.270735 <> codist_loss=2.231408 | Batch (size 100): 176/176 (100%) | Total steps: 176\n",
      "Rank 0 | Validation mean |  cross_entropy=1.773511 <> accuracy=0.363867 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.732107 <> accuracy=0.371094 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 2 | Metrics (epoch mean): cross_entropy=1.606754 <> acc=0.421502 <> codist_loss=1.892504 | Batch (size 100): 176/176 (100%) | Total steps: 352\n",
      "Rank 0 | Validation mean |  cross_entropy=1.494760 <> accuracy=0.470703 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.476057 <> accuracy=0.475391 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 3 | Metrics (epoch mean): cross_entropy=1.402241 <> acc=0.497283 <> codist_loss=1.644994 | Batch (size 100): 176/176 (100%) | Total steps: 528\n",
      "Rank 0 | Validation mean |  cross_entropy=1.328370 <> accuracy=0.529688 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.302175 <> accuracy=0.531836 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 4 | Metrics (epoch mean): cross_entropy=1.247473 <> acc=0.553134 <> codist_loss=1.470130 | Batch (size 100): 176/176 (100%) | Total steps: 704\n",
      "Rank 0 | Validation mean |  cross_entropy=1.173539 <> accuracy=0.597070 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.201314 <> accuracy=0.582812 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 5 | Metrics (epoch mean): cross_entropy=1.144243 <> acc=0.593699 <> codist_loss=1.365558 | Batch (size 100): 176/176 (100%) | Total steps: 880\n",
      "Rank 0 | Validation mean |  cross_entropy=1.100822 <> accuracy=0.623047 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.106241 <> accuracy=0.616797 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 6 | Metrics (epoch mean): cross_entropy=1.069435 <> acc=0.619213 <> codist_loss=1.274872 | Batch (size 100): 176/176 (100%) | Total steps: 1056\n",
      "Rank 0 | Validation mean |  cross_entropy=1.075794 <> accuracy=0.630469 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.059038 <> accuracy=0.633398 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 7 | Metrics (epoch mean): cross_entropy=0.994892 <> acc=0.652264 <> codist_loss=1.216232 | Batch (size 100): 176/176 (100%) | Total steps: 1232\n",
      "Rank 0 | Validation mean |  cross_entropy=1.000494 <> accuracy=0.664062 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.985138 <> accuracy=0.662305 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 8 | Metrics (epoch mean): cross_entropy=0.931975 <> acc=0.673248 <> codist_loss=1.147879 | Batch (size 100): 176/176 (100%) | Total steps: 1408\n",
      "Rank 0 | Validation mean |  cross_entropy=0.970110 <> accuracy=0.668750 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.960394 <> accuracy=0.676953 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 9 | Metrics (epoch mean): cross_entropy=0.889174 <> acc=0.691096 <> codist_loss=1.139630 | Batch (size 100): 176/176 (100%) | Total steps: 1584\n",
      "Rank 0 | Validation mean |  cross_entropy=0.925321 <> accuracy=0.680078 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.931905 <> accuracy=0.683594 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 10 | Metrics (epoch mean): cross_entropy=0.864812 <> acc=0.697914 <> codist_loss=1.086602 | Batch (size 100): 176/176 (100%) | Total steps: 1760\n",
      "Rank 0 | Validation mean |  cross_entropy=0.901033 <> accuracy=0.690625 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.942032 <> accuracy=0.678711 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 11 | Metrics (epoch mean): cross_entropy=0.817073 <> acc=0.718377 <> codist_loss=1.035286 | Batch (size 100): 176/176 (100%) | Total steps: 1936\n",
      "Rank 0 | Validation mean |  cross_entropy=0.889274 <> accuracy=0.692187 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.893771 <> accuracy=0.699805 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 12 | Metrics (epoch mean): cross_entropy=0.782335 <> acc=0.729783 <> codist_loss=1.007160 | Batch (size 100): 176/176 (100%) | Total steps: 2112\n",
      "Rank 0 | Validation mean |  cross_entropy=0.857015 <> accuracy=0.710742 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.869050 <> accuracy=0.701953 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 13 | Metrics (epoch mean): cross_entropy=0.753718 <> acc=0.744222 <> codist_loss=0.972072 | Batch (size 100): 176/176 (100%) | Total steps: 2288\n",
      "Rank 0 | Validation mean |  cross_entropy=0.838271 <> accuracy=0.716406 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.832786 <> accuracy=0.717383 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 14 | Metrics (epoch mean): cross_entropy=0.711342 <> acc=0.756891 <> codist_loss=0.935523 | Batch (size 100): 176/176 (100%) | Total steps: 2464\n",
      "Rank 0 | Validation mean |  cross_entropy=0.824492 <> accuracy=0.715039 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.802516 <> accuracy=0.732813 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 15 | Metrics (epoch mean): cross_entropy=0.690572 <> acc=0.763221 <> codist_loss=0.909465 | Batch (size 100): 176/176 (100%) | Total steps: 2640\n",
      "Rank 0 | Validation mean |  cross_entropy=0.809459 <> accuracy=0.724805 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.800810 <> accuracy=0.729102 | Batch: 40/40 (100%)\n",
      "\n",
      "CPU times: user 35.1 ms, sys: 16.9 ms, total: 52 ms\n",
      "Wall time: 3min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "trainer_kwargs['name'] = 'codist-only'\n",
    "\n",
    "dataloader_kwargs['split_training'] = False\n",
    "dataloader_kwargs['data_parallel'] = True\n",
    "\n",
    "train_kwargs['epochs_sgd'] = 0\n",
    "train_kwargs['epochs_codist'] = 15\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 [conda:torch]",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
