{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "seed: 2246400\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "from swadist.utils import spawn_fn\n",
    "\n",
    "# mp.spawn may throw an error without this\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print('Using cuda')\n",
    "else:\n",
    "    print('Using cpu')\n",
    "\n",
    "seed = int((datetime.date.today() - datetime.date(2022, 4, 11)).total_seconds())\n",
    "print(f'seed: {seed}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- **Common arguments**\n",
    "- **Asynchronous data-parallel SGD**\n",
    "- **Asynchronous SGD + Codistillation**\n",
    "- **Asynchronous SGD + Codistillation w/ data partitioning**\n",
    "- **Codistillation w/ data partioning only**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of model replicas\n",
    "world_size = 2\n",
    "\n",
    "dataloader_kwargs = {\n",
    "    'dataset': 'cifar10',\n",
    "    # size of training batches on each rank\n",
    "    'batch_size': 256 // world_size,\n",
    "    # cpu processes per rank for data loading\n",
    "    'num_workers': 2,\n",
    "}\n",
    "\n",
    "model_kwargs = {\n",
    "    'n_classes': 10,\n",
    "    'in_kernel_size': 3,\n",
    "    'stack_sizes': [1, 1, 1],\n",
    "    'batch_norm': False,\n",
    "}\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'lr': 2**-5.,\n",
    "    'momentum': 0.975,\n",
    "    'nesterov': True,\n",
    "}\n",
    "\n",
    "trainer_kwargs = {\n",
    "    # whether to log training to Tensorboard\n",
    "    'log': False,\n",
    "}\n",
    "\n",
    "train_kwargs = {}\n",
    "\n",
    "scheduler_kwargs = {\n",
    "    'alpha': 0.25,\n",
    "    'decay_epochs': 15,\n",
    "}\n",
    "\n",
    "swa_scheduler_kwargs = {\n",
    "    'swa_lr':  optimizer_kwargs['lr'] / 10, \n",
    "    'anneal_strategy': 'cos',\n",
    "    'anneal_epochs': 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous data-parallel SGD\n",
    "\n",
    "Run asynchronous SGD in parallel with distributed sampling for 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0: joined process group on device cuda with backend nccl\n",
      "Rank 0: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 1/2 starting 15-epoch training loop...\n",
      "SGD epochs: 15 | Codistillation epochs: 0 | SWA epochs: 0\n",
      "DistributedDataParallel: False\n",
      "Stopping accuracy: None\n",
      "\n",
      "Rank 1: joined process group on device cuda with backend nccl\n",
      "Rank 1: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 2/2 starting 15-epoch training loop...\n",
      "Train epoch: 1 | Metrics (epoch mean): cross_entropy=1.923787 <> acc=0.274013 | Batch (size 100): 176/176 (100%) | Total steps: 176\n",
      "Rank 0 | Validation mean |  cross_entropy=1.690852 <> accuracy=0.379297 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.748831 <> accuracy=0.336133 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 2 | Metrics (epoch mean): cross_entropy=1.535766 <> acc=0.440740 | Batch (size 100): 176/176 (100%) | Total steps: 352\n",
      "Rank 0 | Validation mean |  cross_entropy=1.383916 <> accuracy=0.501367 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.484708 <> accuracy=0.450000 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 3 | Metrics (epoch mean): cross_entropy=1.313569 <> acc=0.526300 | Batch (size 100): 176/176 (100%) | Total steps: 528\n",
      "Rank 0 | Validation mean |  cross_entropy=1.248176 <> accuracy=0.561328 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.359660 <> accuracy=0.519141 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 4 | Metrics (epoch mean): cross_entropy=1.183106 <> acc=0.577793 | Batch (size 100): 176/176 (100%) | Total steps: 704\n",
      "Rank 0 | Validation mean |  cross_entropy=1.147035 <> accuracy=0.599805 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.164087 <> accuracy=0.595508 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 5 | Metrics (epoch mean): cross_entropy=1.084619 <> acc=0.616108 | Batch (size 100): 176/176 (100%) | Total steps: 880\n",
      "Rank 0 | Validation mean |  cross_entropy=1.088103 <> accuracy=0.621289 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.085764 <> accuracy=0.622461 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 6 | Metrics (epoch mean): cross_entropy=1.026528 <> acc=0.637887 | Batch (size 100): 176/176 (100%) | Total steps: 1056\n",
      "Rank 0 | Validation mean |  cross_entropy=1.048203 <> accuracy=0.639648 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.071811 <> accuracy=0.625195 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 7 | Metrics (epoch mean): cross_entropy=0.947547 <> acc=0.665840 | Batch (size 100): 176/176 (100%) | Total steps: 1232\n",
      "Rank 0 | Validation mean |  cross_entropy=1.001698 <> accuracy=0.669336 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.019294 <> accuracy=0.648438 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 8 | Metrics (epoch mean): cross_entropy=0.890702 <> acc=0.687514 | Batch (size 100): 176/176 (100%) | Total steps: 1408\n",
      "Rank 0 | Validation mean |  cross_entropy=0.965924 <> accuracy=0.669336 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.977397 <> accuracy=0.661133 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 9 | Metrics (epoch mean): cross_entropy=0.835030 <> acc=0.711046 | Batch (size 100): 176/176 (100%) | Total steps: 1584\n",
      "Rank 0 | Validation mean |  cross_entropy=0.917836 <> accuracy=0.692773 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.957248 <> accuracy=0.667188 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 10 | Metrics (epoch mean): cross_entropy=0.804845 <> acc=0.720424 | Batch (size 100): 176/176 (100%) | Total steps: 1760\n",
      "Rank 0 | Validation mean |  cross_entropy=0.895171 <> accuracy=0.702148 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.942360 <> accuracy=0.677734 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 11 | Metrics (epoch mean): cross_entropy=0.744452 <> acc=0.740730 | Batch (size 100): 176/176 (100%) | Total steps: 1936\n",
      "Rank 0 | Validation mean |  cross_entropy=0.892084 <> accuracy=0.704297 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.910426 <> accuracy=0.693359 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 12 | Metrics (epoch mean): cross_entropy=0.704774 <> acc=0.753798 | Batch (size 100): 176/176 (100%) | Total steps: 2112\n",
      "Rank 0 | Validation mean |  cross_entropy=0.848304 <> accuracy=0.723437 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.876338 <> accuracy=0.704883 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 13 | Metrics (epoch mean): cross_entropy=0.678533 <> acc=0.763398 | Batch (size 100): 176/176 (100%) | Total steps: 2288\n",
      "Rank 0 | Validation mean |  cross_entropy=0.826702 <> accuracy=0.725977 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.901481 <> accuracy=0.702148 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 14 | Metrics (epoch mean): cross_entropy=0.617434 <> acc=0.786760 | Batch (size 100): 176/176 (100%) | Total steps: 2464\n",
      "Rank 0 | Validation mean |  cross_entropy=0.849686 <> accuracy=0.713477 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.854479 <> accuracy=0.711328 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 15 | Metrics (epoch mean): cross_entropy=0.577306 <> acc=0.798979 | Batch (size 100): 176/176 (100%) | Total steps: 2640\n",
      "Rank 0 | Validation mean |  cross_entropy=0.846127 <> accuracy=0.727539 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.857112 <> accuracy=0.727539 | Batch: 40/40 (100%)\n",
      "\n",
      "CPU times: user 40 ms, sys: 9.85 ms, total: 49.9 ms\n",
      "Wall time: 3min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer_kwargs['name'] = 'async-sgd'\n",
    "\n",
    "# when true, uses DistributedSampler\n",
    "dataloader_kwargs['data_parallel'] = True\n",
    "\n",
    "train_kwargs['epochs_sgd'] = 15\n",
    "train_kwargs['epochs_codist'] = 0\n",
    "train_kwargs['epochs_swa'] = 0\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs\n",
    "        seed, # seed on rank i = seed + i\n",
    "        False) # ddp=False, don't use DistributedDataParallel\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous SGD + Codistillation\n",
    "\n",
    "Switch to codistillation after 5 epochs of asynchronous SGD and train for 15 epochs total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: joined process group on device cuda with backend nccl\n",
      "Rank 1: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 2/2 starting 15-epoch training loop...\n",
      "Rank 0: joined process group on device cuda with backend nccl\n",
      "Rank 0: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 1/2 starting 15-epoch training loop...\n",
      "SGD epochs: 5 | Codistillation epochs: 10 | SWA epochs: 0\n",
      "DistributedDataParallel: False\n",
      "Stopping accuracy: None\n",
      "\n",
      "Train epoch: 1 | Metrics (epoch mean): cross_entropy=1.924133 <> acc=0.271895 | Batch (size 100): 176/176 (100%) | Total steps: 176\n",
      "Rank 0 | Validation mean |  cross_entropy=1.719567 <> accuracy=0.368359 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.836185 <> accuracy=0.301953 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 2 | Metrics (epoch mean): cross_entropy=1.537889 <> acc=0.437019 | Batch (size 100): 176/176 (100%) | Total steps: 352\n",
      "Rank 0 | Validation mean |  cross_entropy=1.414817 <> accuracy=0.481445 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.563535 <> accuracy=0.424414 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 3 | Metrics (epoch mean): cross_entropy=1.333861 <> acc=0.517663 | Batch (size 100): 176/176 (100%) | Total steps: 528\n",
      "Rank 0 | Validation mean |  cross_entropy=1.307887 <> accuracy=0.537109 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.421773 <> accuracy=0.480273 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 4 | Metrics (epoch mean): cross_entropy=1.189234 <> acc=0.577140 | Batch (size 100): 176/176 (100%) | Total steps: 704\n",
      "Rank 0 | Validation mean |  cross_entropy=1.157159 <> accuracy=0.588867 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.289992 <> accuracy=0.536914 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 5 | Metrics (epoch mean): cross_entropy=1.085038 <> acc=0.615352 | Batch (size 100): 176/176 (100%) | Total steps: 880\n",
      "Rank 0 | Validation mean |  cross_entropy=1.088326 <> accuracy=0.624023 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.203191 <> accuracy=0.572656 | Batch: 40/40 (100%)\n",
      "\n",
      "Starting codistillation phase...\n",
      "\n",
      "Train epoch: 6 | Metrics (epoch mean): cross_entropy=1.027029 <> acc=0.643038 <> codist_loss=1.429739 | Batch (size 100): 176/176 (100%) | Total steps: 1056\n",
      "Rank 0 | Validation mean |  cross_entropy=1.026958 <> accuracy=0.643359 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.106527 <> accuracy=0.620898 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 7 | Metrics (epoch mean): cross_entropy=0.943183 <> acc=0.677837 <> codist_loss=1.348168 | Batch (size 100): 176/176 (100%) | Total steps: 1232\n",
      "Rank 0 | Validation mean |  cross_entropy=0.971702 <> accuracy=0.671484 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.052032 <> accuracy=0.637500 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 8 | Metrics (epoch mean): cross_entropy=0.891981 <> acc=0.693114 <> codist_loss=1.273482 | Batch (size 100): 176/176 (100%) | Total steps: 1408\n",
      "Rank 0 | Validation mean |  cross_entropy=0.953964 <> accuracy=0.679102 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.032376 <> accuracy=0.649609 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 9 | Metrics (epoch mean): cross_entropy=0.858597 <> acc=0.708294 <> codist_loss=1.225015 | Batch (size 100): 176/176 (100%) | Total steps: 1584\n",
      "Rank 0 | Validation mean |  cross_entropy=0.924145 <> accuracy=0.691406 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.989053 <> accuracy=0.656445 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 10 | Metrics (epoch mean): cross_entropy=0.848299 <> acc=0.710678 <> codist_loss=1.214004 | Batch (size 100): 176/176 (100%) | Total steps: 1760\n",
      "Rank 0 | Validation mean |  cross_entropy=0.914009 <> accuracy=0.686328 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.979741 <> accuracy=0.674023 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 11 | Metrics (epoch mean): cross_entropy=0.811051 <> acc=0.726918 <> codist_loss=1.180110 | Batch (size 100): 176/176 (100%) | Total steps: 1936\n",
      "Rank 0 | Validation mean |  cross_entropy=0.898532 <> accuracy=0.697070 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.941600 <> accuracy=0.677734 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 12 | Metrics (epoch mean): cross_entropy=0.782513 <> acc=0.738287 <> codist_loss=1.148692 | Batch (size 100): 176/176 (100%) | Total steps: 2112\n",
      "Rank 0 | Validation mean |  cross_entropy=0.867951 <> accuracy=0.707422 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.918785 <> accuracy=0.691797 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 13 | Metrics (epoch mean): cross_entropy=0.754368 <> acc=0.747051 <> codist_loss=1.113836 | Batch (size 100): 176/176 (100%) | Total steps: 2288\n",
      "Rank 0 | Validation mean |  cross_entropy=0.855377 <> accuracy=0.716602 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.915254 <> accuracy=0.690820 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 14 | Metrics (epoch mean): cross_entropy=0.726761 <> acc=0.757665 <> codist_loss=1.085267 | Batch (size 100): 176/176 (100%) | Total steps: 2464\n",
      "Rank 0 | Validation mean |  cross_entropy=0.860789 <> accuracy=0.708789 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.893450 <> accuracy=0.703906 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 15 | Metrics (epoch mean): cross_entropy=0.707041 <> acc=0.762031 <> codist_loss=1.040514 | Batch (size 100): 176/176 (100%) | Total steps: 2640\n",
      "Rank 0 | Validation mean |  cross_entropy=0.835720 <> accuracy=0.721875 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.874547 <> accuracy=0.704687 | Batch: 40/40 (100%)\n",
      "\n",
      "CPU times: user 38.3 ms, sys: 22.7 ms, total: 61 ms\n",
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "trainer_kwargs['name'] = 'codist'\n",
    "\n",
    "dataloader_kwargs['data_parallel'] = True\n",
    "    \n",
    "train_kwargs['epochs_sgd'] = 5\n",
    "train_kwargs['epochs_codist'] = 10\n",
    "train_kwargs['codist_kwargs'] = {\n",
    "    # how many steps before re-syncing stale replicas\n",
    "    'sync_freq': 50,\n",
    "    # transform to apply to mean replica output\n",
    "    'transform': 'softmax',\n",
    "    # when True, prints gather and update param steps\n",
    "    'debug': False,\n",
    "}\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous SGD + Codistillation w/ data partitioning\n",
    "\n",
    "As before, but this time we train each model replica on disjoint partitions of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: joined process group on device cuda with backend nccl\n",
      "Rank 1: torch.manual_seed(2246400)\n",
      "Using SubsetRandomSampler with samples 22500 to 44999\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 2/2 starting 15-epoch training loop...\n",
      "Rank 0: joined process group on device cuda with backend nccl\n",
      "Rank 0: torch.manual_seed(2246400)\n",
      "Using SubsetRandomSampler with samples 0 to 22499\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 1/2 starting 15-epoch training loop...\n",
      "SGD epochs: 5 | Codistillation epochs: 10 | SWA epochs: 0\n",
      "DistributedDataParallel: False\n",
      "Stopping accuracy: None\n",
      "\n",
      "Train epoch: 1 | Metrics (epoch mean): cross_entropy=1.958013 <> acc=0.261422 | Batch (size 100): 176/176 (100%) | Total steps: 176\n",
      "Rank 0 | Validation mean |  cross_entropy=1.710087 <> accuracy=0.352539 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.672574 <> accuracy=0.388281 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 2 | Metrics (epoch mean): cross_entropy=1.572482 <> acc=0.421229 | Batch (size 100): 176/176 (100%) | Total steps: 352\n",
      "Rank 0 | Validation mean |  cross_entropy=1.472164 <> accuracy=0.464063 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.431690 <> accuracy=0.483984 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 3 | Metrics (epoch mean): cross_entropy=1.349743 <> acc=0.513018 | Batch (size 100): 176/176 (100%) | Total steps: 528\n",
      "Rank 0 | Validation mean |  cross_entropy=1.271691 <> accuracy=0.566016 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.235588 <> accuracy=0.554102 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 4 | Metrics (epoch mean): cross_entropy=1.192199 <> acc=0.570875 | Batch (size 100): 176/176 (100%) | Total steps: 704\n",
      "Rank 0 | Validation mean |  cross_entropy=1.195747 <> accuracy=0.580469 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.156430 <> accuracy=0.601367 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 5 | Metrics (epoch mean): cross_entropy=1.084088 <> acc=0.614980 | Batch (size 100): 176/176 (100%) | Total steps: 880\n",
      "Rank 0 | Validation mean |  cross_entropy=1.129597 <> accuracy=0.607422 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.100818 <> accuracy=0.607422 | Batch: 40/40 (100%)\n",
      "\n",
      "Starting codistillation phase...\n",
      "\n",
      "Train epoch: 6 | Metrics (epoch mean): cross_entropy=0.983197 <> acc=0.655012 <> codist_loss=1.369272 | Batch (size 100): 176/176 (100%) | Total steps: 1056\n",
      "Rank 0 | Validation mean |  cross_entropy=1.034728 <> accuracy=0.649023 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.993384 <> accuracy=0.650586 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 7 | Metrics (epoch mean): cross_entropy=0.883718 <> acc=0.696081 <> codist_loss=1.265301 | Batch (size 100): 176/176 (100%) | Total steps: 1232\n",
      "Rank 0 | Validation mean |  cross_entropy=0.980266 <> accuracy=0.670508 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.949169 <> accuracy=0.675000 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 8 | Metrics (epoch mean): cross_entropy=0.823660 <> acc=0.719247 <> codist_loss=1.207061 | Batch (size 100): 176/176 (100%) | Total steps: 1408\n",
      "Rank 0 | Validation mean |  cross_entropy=0.956385 <> accuracy=0.670703 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.935933 <> accuracy=0.676367 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 9 | Metrics (epoch mean): cross_entropy=0.779823 <> acc=0.734567 <> codist_loss=1.148178 | Batch (size 100): 176/176 (100%) | Total steps: 1584\n",
      "Rank 0 | Validation mean |  cross_entropy=0.948116 <> accuracy=0.679688 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.910214 <> accuracy=0.683984 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 10 | Metrics (epoch mean): cross_entropy=0.747805 <> acc=0.746017 <> codist_loss=1.137496 | Batch (size 100): 176/176 (100%) | Total steps: 1760\n",
      "Rank 0 | Validation mean |  cross_entropy=0.925428 <> accuracy=0.683984 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.901677 <> accuracy=0.687695 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 11 | Metrics (epoch mean): cross_entropy=0.712584 <> acc=0.760767 <> codist_loss=1.106195 | Batch (size 100): 176/176 (100%) | Total steps: 1936\n",
      "Rank 0 | Validation mean |  cross_entropy=0.922033 <> accuracy=0.689648 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.878337 <> accuracy=0.695703 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 12 | Metrics (epoch mean): cross_entropy=0.675333 <> acc=0.776025 <> codist_loss=1.087697 | Batch (size 100): 176/176 (100%) | Total steps: 2112\n",
      "Rank 0 | Validation mean |  cross_entropy=0.917555 <> accuracy=0.686523 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.878083 <> accuracy=0.694141 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 13 | Metrics (epoch mean): cross_entropy=0.641996 <> acc=0.787933 <> codist_loss=1.083134 | Batch (size 100): 176/176 (100%) | Total steps: 2288\n",
      "Rank 0 | Validation mean |  cross_entropy=0.907957 <> accuracy=0.696484 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.876234 <> accuracy=0.703906 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 14 | Metrics (epoch mean): cross_entropy=0.614194 <> acc=0.799080 <> codist_loss=1.055635 | Batch (size 100): 176/176 (100%) | Total steps: 2464\n",
      "Rank 0 | Validation mean |  cross_entropy=0.902611 <> accuracy=0.692969 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.858026 <> accuracy=0.703906 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 15 | Metrics (epoch mean): cross_entropy=0.581728 <> acc=0.812765 <> codist_loss=1.043326 | Batch (size 100): 176/176 (100%) | Total steps: 2640\n",
      "Rank 0 | Validation mean |  cross_entropy=0.901582 <> accuracy=0.690625 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.854479 <> accuracy=0.705664 | Batch: 40/40 (100%)\n",
      "\n",
      "CPU times: user 49.3 ms, sys: 5.13 ms, total: 54.5 ms\n",
      "Wall time: 3min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "trainer_kwargs['name'] = 'codist-split'\n",
    "\n",
    "# when True, restrict each rank to half of the data\n",
    "dataloader_kwargs['split_training'] = True\n",
    "dataloader_kwargs['data_parallel'] = False\n",
    "\n",
    "train_kwargs['codist_kwargs'] = {\n",
    "    # how many steps before re-syncing stale replicas\n",
    "    'sync_freq': 50,\n",
    "    # transform to apply to mean replica output\n",
    "    'transform': 'softmax',\n",
    "    # when True, prints gather and update param steps\n",
    "    'debug': False,\n",
    "}\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-parallel codistillation only\n",
    "\n",
    "Now run data-parallel codistillation for all 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: joined process group on device cuda with backend nccl\n",
      "Rank 1: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 2/2 starting 15-epoch training loop...\n",
      "Rank 0: joined process group on device cuda with backend nccl\n",
      "Rank 0: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 1/2 starting 15-epoch training loop...\n",
      "SGD epochs: 0 | Codistillation epochs: 15 | SWA epochs: 0\n",
      "DistributedDataParallel: False\n",
      "Stopping accuracy: None\n",
      "\n",
      "Starting codistillation phase...\n",
      "\n",
      "Train epoch: 1 | Metrics (epoch mean): cross_entropy=1.994283 <> acc=0.270767 <> codist_loss=2.231593 | Batch (size 100): 176/176 (100%) | Total steps: 176\n",
      "Rank 0 | Validation mean |  cross_entropy=1.779046 <> accuracy=0.362109 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.739466 <> accuracy=0.365039 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 2 | Metrics (epoch mean): cross_entropy=1.611165 <> acc=0.421332 <> codist_loss=1.891167 | Batch (size 100): 176/176 (100%) | Total steps: 352\n",
      "Rank 0 | Validation mean |  cross_entropy=1.502983 <> accuracy=0.470313 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.494850 <> accuracy=0.463672 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 3 | Metrics (epoch mean): cross_entropy=1.403713 <> acc=0.496960 <> codist_loss=1.652475 | Batch (size 100): 176/176 (100%) | Total steps: 528\n",
      "Rank 0 | Validation mean |  cross_entropy=1.323517 <> accuracy=0.531836 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.298696 <> accuracy=0.542383 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 4 | Metrics (epoch mean): cross_entropy=1.248837 <> acc=0.557179 <> codist_loss=1.463811 | Batch (size 100): 176/176 (100%) | Total steps: 704\n",
      "Rank 0 | Validation mean |  cross_entropy=1.198268 <> accuracy=0.579492 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.202119 <> accuracy=0.580859 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 5 | Metrics (epoch mean): cross_entropy=1.140834 <> acc=0.598347 <> codist_loss=1.356521 | Batch (size 100): 176/176 (100%) | Total steps: 880\n",
      "Rank 0 | Validation mean |  cross_entropy=1.104389 <> accuracy=0.627539 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.116827 <> accuracy=0.613477 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 6 | Metrics (epoch mean): cross_entropy=1.066139 <> acc=0.620575 <> codist_loss=1.266318 | Batch (size 100): 176/176 (100%) | Total steps: 1056\n",
      "Rank 0 | Validation mean |  cross_entropy=1.069943 <> accuracy=0.634180 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.047360 <> accuracy=0.636719 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 7 | Metrics (epoch mean): cross_entropy=0.993796 <> acc=0.653995 <> codist_loss=1.208199 | Batch (size 100): 176/176 (100%) | Total steps: 1232\n",
      "Rank 0 | Validation mean |  cross_entropy=1.007105 <> accuracy=0.657422 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.992894 <> accuracy=0.658398 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 8 | Metrics (epoch mean): cross_entropy=0.929242 <> acc=0.677172 <> codist_loss=1.147573 | Batch (size 100): 176/176 (100%) | Total steps: 1408\n",
      "Rank 0 | Validation mean |  cross_entropy=0.956251 <> accuracy=0.676953 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.956126 <> accuracy=0.674219 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 9 | Metrics (epoch mean): cross_entropy=0.883847 <> acc=0.692338 <> codist_loss=1.121387 | Batch (size 100): 176/176 (100%) | Total steps: 1584\n",
      "Rank 0 | Validation mean |  cross_entropy=0.919269 <> accuracy=0.689453 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.928215 <> accuracy=0.684766 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 10 | Metrics (epoch mean): cross_entropy=0.856876 <> acc=0.701433 <> codist_loss=1.082876 | Batch (size 100): 176/176 (100%) | Total steps: 1760\n",
      "Rank 0 | Validation mean |  cross_entropy=0.908328 <> accuracy=0.689844 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.926046 <> accuracy=0.683203 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 11 | Metrics (epoch mean): cross_entropy=0.812047 <> acc=0.719842 <> codist_loss=1.028112 | Batch (size 100): 176/176 (100%) | Total steps: 1936\n",
      "Rank 0 | Validation mean |  cross_entropy=0.903219 <> accuracy=0.690820 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.874987 <> accuracy=0.697266 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 12 | Metrics (epoch mean): cross_entropy=0.773385 <> acc=0.737362 <> codist_loss=0.994091 | Batch (size 100): 176/176 (100%) | Total steps: 2112\n",
      "Rank 0 | Validation mean |  cross_entropy=0.859421 <> accuracy=0.701953 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.851876 <> accuracy=0.711523 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 13 | Metrics (epoch mean): cross_entropy=0.750470 <> acc=0.742809 <> codist_loss=0.968079 | Batch (size 100): 176/176 (100%) | Total steps: 2288\n",
      "Rank 0 | Validation mean |  cross_entropy=0.828535 <> accuracy=0.717969 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.833980 <> accuracy=0.712695 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 14 | Metrics (epoch mean): cross_entropy=0.710378 <> acc=0.757862 <> codist_loss=0.930918 | Batch (size 100): 176/176 (100%) | Total steps: 2464\n",
      "Rank 0 | Validation mean |  cross_entropy=0.823818 <> accuracy=0.720898 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.814290 <> accuracy=0.723437 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 15 | Metrics (epoch mean): cross_entropy=0.676523 <> acc=0.764066 <> codist_loss=0.892422 | Batch (size 100): 176/176 (100%) | Total steps: 2640\n",
      "Rank 0 | Validation mean |  cross_entropy=0.800684 <> accuracy=0.724805 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.786408 <> accuracy=0.732031 | Batch: 40/40 (100%)\n",
      "\n",
      "CPU times: user 51.2 ms, sys: 13.7 ms, total: 64.9 ms\n",
      "Wall time: 3min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "trainer_kwargs['name'] = 'codist-only'\n",
    "\n",
    "dataloader_kwargs['split_training'] = False\n",
    "dataloader_kwargs['data_parallel'] = True\n",
    "\n",
    "train_kwargs['epochs_sgd'] = 0\n",
    "train_kwargs['epochs_codist'] = 15\n",
    "train_kwargs['codist_kwargs'] = {\n",
    "    # how many steps before re-syncing stale replicas\n",
    "    'sync_freq': 50,\n",
    "    # transform to apply to mean replica output\n",
    "    'transform': 'softmax',\n",
    "    # when True, prints gather and update param steps\n",
    "    'debug': False,\n",
    "}\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codistillation followed by SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: joined process group on device cuda with backend nccl\n",
      "Rank 1: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 2/2 starting 55-epoch training loop...\n",
      "Rank 0: joined process group on device cuda with backend nccl\n",
      "Rank 0: torch.manual_seed(2246400)\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "\n",
      "Worker 1/2 starting 55-epoch training loop...\n",
      "SGD epochs: 0 | Codistillation epochs: 40 | SWA epochs: 15\n",
      "DistributedDataParallel: False\n",
      "Stopping accuracy: None\n",
      "\n",
      "Starting codistillation phase...\n",
      "\n",
      "Train epoch: 1 | Metrics (epoch mean): cross_entropy=1.992147 <> acc=0.271135 <> codist_loss=2.230487 | Batch (size 100): 176/176 (100%) | Total steps: 176\n",
      "Rank 0 | Validation mean |  cross_entropy=1.763798 <> accuracy=0.366016 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.739883 <> accuracy=0.364844 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 2 | Metrics (epoch mean): cross_entropy=1.606249 <> acc=0.422599 <> codist_loss=1.893026 | Batch (size 100): 176/176 (100%) | Total steps: 352\n",
      "Rank 0 | Validation mean |  cross_entropy=1.491675 <> accuracy=0.474023 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.497818 <> accuracy=0.469922 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 3 | Metrics (epoch mean): cross_entropy=1.395597 <> acc=0.501843 <> codist_loss=1.647230 | Batch (size 100): 176/176 (100%) | Total steps: 528\n",
      "Rank 0 | Validation mean |  cross_entropy=1.321590 <> accuracy=0.536914 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.289576 <> accuracy=0.541211 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 4 | Metrics (epoch mean): cross_entropy=1.245049 <> acc=0.558136 <> codist_loss=1.479222 | Batch (size 100): 176/176 (100%) | Total steps: 704\n",
      "Rank 0 | Validation mean |  cross_entropy=1.179733 <> accuracy=0.589258 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.213574 <> accuracy=0.579687 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 5 | Metrics (epoch mean): cross_entropy=1.142545 <> acc=0.595321 <> codist_loss=1.349980 | Batch (size 100): 176/176 (100%) | Total steps: 880\n",
      "Rank 0 | Validation mean |  cross_entropy=1.097301 <> accuracy=0.631641 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.121766 <> accuracy=0.614062 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 6 | Metrics (epoch mean): cross_entropy=1.069167 <> acc=0.620131 <> codist_loss=1.277083 | Batch (size 100): 176/176 (100%) | Total steps: 1056\n",
      "Rank 0 | Validation mean |  cross_entropy=1.079047 <> accuracy=0.630859 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=1.038268 <> accuracy=0.633008 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 7 | Metrics (epoch mean): cross_entropy=0.998216 <> acc=0.650811 <> codist_loss=1.218599 | Batch (size 100): 176/176 (100%) | Total steps: 1232\n",
      "Rank 0 | Validation mean |  cross_entropy=0.995515 <> accuracy=0.666797 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.986067 <> accuracy=0.658008 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 8 | Metrics (epoch mean): cross_entropy=0.923082 <> acc=0.677521 <> codist_loss=1.127049 | Batch (size 100): 176/176 (100%) | Total steps: 1408\n",
      "Rank 0 | Validation mean |  cross_entropy=0.966990 <> accuracy=0.666992 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.948986 <> accuracy=0.682227 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 9 | Metrics (epoch mean): cross_entropy=0.885971 <> acc=0.692921 <> codist_loss=1.123735 | Batch (size 100): 176/176 (100%) | Total steps: 1584\n",
      "Rank 0 | Validation mean |  cross_entropy=0.929818 <> accuracy=0.682227 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.934012 <> accuracy=0.681836 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 10 | Metrics (epoch mean): cross_entropy=0.852173 <> acc=0.703754 <> codist_loss=1.063774 | Batch (size 100): 176/176 (100%) | Total steps: 1760\n",
      "Rank 0 | Validation mean |  cross_entropy=0.895138 <> accuracy=0.700391 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.899274 <> accuracy=0.696680 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 11 | Metrics (epoch mean): cross_entropy=0.809624 <> acc=0.722290 <> codist_loss=1.030420 | Batch (size 100): 176/176 (100%) | Total steps: 1936\n",
      "Rank 0 | Validation mean |  cross_entropy=0.885491 <> accuracy=0.693750 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.870261 <> accuracy=0.696484 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 12 | Metrics (epoch mean): cross_entropy=0.772909 <> acc=0.735352 <> codist_loss=1.006474 | Batch (size 100): 176/176 (100%) | Total steps: 2112\n",
      "Rank 0 | Validation mean |  cross_entropy=0.844156 <> accuracy=0.720508 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.851979 <> accuracy=0.707031 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 13 | Metrics (epoch mean): cross_entropy=0.747852 <> acc=0.744441 <> codist_loss=0.961777 | Batch (size 100): 176/176 (100%) | Total steps: 2288\n",
      "Rank 0 | Validation mean |  cross_entropy=0.832871 <> accuracy=0.719531 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.814937 <> accuracy=0.724023 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 14 | Metrics (epoch mean): cross_entropy=0.699389 <> acc=0.763835 <> codist_loss=0.922760 | Batch (size 100): 176/176 (100%) | Total steps: 2464\n",
      "Rank 0 | Validation mean |  cross_entropy=0.803645 <> accuracy=0.728125 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.788349 <> accuracy=0.730664 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 15 | Metrics (epoch mean): cross_entropy=0.672950 <> acc=0.770083 <> codist_loss=0.890337 | Batch (size 100): 176/176 (100%) | Total steps: 2640\n",
      "Rank 0 | Validation mean |  cross_entropy=0.795463 <> accuracy=0.719141 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.772491 <> accuracy=0.735742 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 16 | Metrics (epoch mean): cross_entropy=0.648581 <> acc=0.777179 <> codist_loss=0.874273 | Batch (size 100): 176/176 (100%) | Total steps: 2816\n",
      "Rank 0 | Validation mean |  cross_entropy=0.773617 <> accuracy=0.733984 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.765288 <> accuracy=0.739062 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 17 | Metrics (epoch mean): cross_entropy=0.646464 <> acc=0.777884 <> codist_loss=0.853340 | Batch (size 100): 176/176 (100%) | Total steps: 2992\n",
      "Rank 0 | Validation mean |  cross_entropy=0.774439 <> accuracy=0.739844 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.776740 <> accuracy=0.736328 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 18 | Metrics (epoch mean): cross_entropy=0.622041 <> acc=0.787001 <> codist_loss=0.836224 | Batch (size 100): 176/176 (100%) | Total steps: 3168\n",
      "Rank 0 | Validation mean |  cross_entropy=0.780302 <> accuracy=0.731445 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.767656 <> accuracy=0.747656 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 19 | Metrics (epoch mean): cross_entropy=0.615950 <> acc=0.790916 <> codist_loss=0.834668 | Batch (size 100): 176/176 (100%) | Total steps: 3344\n",
      "Rank 0 | Validation mean |  cross_entropy=0.771687 <> accuracy=0.741797 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.757748 <> accuracy=0.746289 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 20 | Metrics (epoch mean): cross_entropy=0.601483 <> acc=0.797292 <> codist_loss=0.846595 | Batch (size 100): 176/176 (100%) | Total steps: 3520\n",
      "Rank 0 | Validation mean |  cross_entropy=0.757180 <> accuracy=0.743164 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.753169 <> accuracy=0.742773 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 21 | Metrics (epoch mean): cross_entropy=0.583035 <> acc=0.802740 <> codist_loss=0.813250 | Batch (size 100): 176/176 (100%) | Total steps: 3696\n",
      "Rank 0 | Validation mean |  cross_entropy=0.752715 <> accuracy=0.741602 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.756097 <> accuracy=0.743555 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 22 | Metrics (epoch mean): cross_entropy=0.575082 <> acc=0.804318 <> codist_loss=0.817175 | Batch (size 100): 176/176 (100%) | Total steps: 3872\n",
      "Rank 0 | Validation mean |  cross_entropy=0.758936 <> accuracy=0.748438 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.727448 <> accuracy=0.751562 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 23 | Metrics (epoch mean): cross_entropy=0.572169 <> acc=0.804123 <> codist_loss=0.794184 | Batch (size 100): 176/176 (100%) | Total steps: 4048\n",
      "Rank 0 | Validation mean |  cross_entropy=0.755880 <> accuracy=0.743750 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.742599 <> accuracy=0.750781 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 24 | Metrics (epoch mean): cross_entropy=0.552600 <> acc=0.814281 <> codist_loss=0.803956 | Batch (size 100): 176/176 (100%) | Total steps: 4224\n",
      "Rank 0 | Validation mean |  cross_entropy=0.731091 <> accuracy=0.748633 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.735808 <> accuracy=0.762305 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 25 | Metrics (epoch mean): cross_entropy=0.530687 <> acc=0.819329 <> codist_loss=0.765210 | Batch (size 100): 176/176 (100%) | Total steps: 4400\n",
      "Rank 0 | Validation mean |  cross_entropy=0.753734 <> accuracy=0.745898 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.727662 <> accuracy=0.757617 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 26 | Metrics (epoch mean): cross_entropy=0.530993 <> acc=0.819785 <> codist_loss=0.769999 | Batch (size 100): 176/176 (100%) | Total steps: 4576\n",
      "Rank 0 | Validation mean |  cross_entropy=0.731066 <> accuracy=0.753516 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.723780 <> accuracy=0.757031 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 27 | Metrics (epoch mean): cross_entropy=0.519546 <> acc=0.824357 <> codist_loss=0.775275 | Batch (size 100): 176/176 (100%) | Total steps: 4752\n",
      "Rank 0 | Validation mean |  cross_entropy=0.726045 <> accuracy=0.750391 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.729157 <> accuracy=0.758398 | Batch: 40/40 (100%)\n",
      "\n",
      "\n",
      "\n",
      "codist stalled (mean accuracy of last 3 epochs was 0.001660 less than the one before, on average across all ranks). Moving onto the next phase of training.\n",
      "Starting SWA phase...\n",
      "\n",
      "Train epoch: 28 | Metrics (epoch mean): cross_entropy=0.539337 <> acc=0.811705 | Batch (size 100): 176/176 (100%) | Total steps: 4928\n",
      "Rank 0 | Validation mean |  cross_entropy=0.720876 <> accuracy=0.755469 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.723899 <> accuracy=0.754687 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 29 | Metrics (epoch mean): cross_entropy=0.530326 <> acc=0.811369 | Batch (size 100): 176/176 (100%) | Total steps: 5104\n",
      "Rank 0 | Validation mean |  cross_entropy=0.708687 <> accuracy=0.764063 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.720885 <> accuracy=0.761133 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 30 | Metrics (epoch mean): cross_entropy=0.471944 <> acc=0.834387 | Batch (size 100): 176/176 (100%) | Total steps: 5280\n",
      "Rank 0 | Validation mean |  cross_entropy=0.704077 <> accuracy=0.767578 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.712925 <> accuracy=0.763281 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 31 | Metrics (epoch mean): cross_entropy=0.427680 <> acc=0.853436 | Batch (size 100): 176/176 (100%) | Total steps: 5456\n",
      "Rank 0 | Validation mean |  cross_entropy=0.703435 <> accuracy=0.769531 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.712067 <> accuracy=0.769336 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 32 | Metrics (epoch mean): cross_entropy=0.406547 <> acc=0.858819 | Batch (size 100): 176/176 (100%) | Total steps: 5632\n",
      "Rank 0 | Validation mean |  cross_entropy=0.706497 <> accuracy=0.767773 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.710717 <> accuracy=0.769336 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 33 | Metrics (epoch mean): cross_entropy=0.387010 <> acc=0.865929 | Batch (size 100): 176/176 (100%) | Total steps: 5808\n",
      "Rank 0 | Validation mean |  cross_entropy=0.709400 <> accuracy=0.769336 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.712349 <> accuracy=0.772070 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 34 | Metrics (epoch mean): cross_entropy=0.366368 <> acc=0.871706 | Batch (size 100): 176/176 (100%) | Total steps: 5984\n",
      "Rank 0 | Validation mean |  cross_entropy=0.708896 <> accuracy=0.769922 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.714436 <> accuracy=0.770703 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 35 | Metrics (epoch mean): cross_entropy=0.367782 <> acc=0.872695 | Batch (size 100): 176/176 (100%) | Total steps: 6160\n",
      "Rank 0 | Validation mean |  cross_entropy=0.711425 <> accuracy=0.770508 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.717671 <> accuracy=0.772461 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 36 | Metrics (epoch mean): cross_entropy=0.341869 <> acc=0.880831 | Batch (size 100): 176/176 (100%) | Total steps: 6336\n",
      "Rank 0 | Validation mean |  cross_entropy=0.716583 <> accuracy=0.768164 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.720331 <> accuracy=0.770898 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 37 | Metrics (epoch mean): cross_entropy=0.339970 <> acc=0.881681 | Batch (size 100): 176/176 (100%) | Total steps: 6512\n",
      "Rank 0 | Validation mean |  cross_entropy=0.722396 <> accuracy=0.767383 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.723982 <> accuracy=0.769141 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 38 | Metrics (epoch mean): cross_entropy=0.315267 <> acc=0.890005 | Batch (size 100): 176/176 (100%) | Total steps: 6688\n",
      "Rank 0 | Validation mean |  cross_entropy=0.727615 <> accuracy=0.768945 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.730278 <> accuracy=0.769141 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 39 | Metrics (epoch mean): cross_entropy=0.302916 <> acc=0.894743 | Batch (size 100): 176/176 (100%) | Total steps: 6864\n",
      "Rank 0 | Validation mean |  cross_entropy=0.733947 <> accuracy=0.771484 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.733982 <> accuracy=0.767383 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 40 | Metrics (epoch mean): cross_entropy=0.308724 <> acc=0.892512 | Batch (size 100): 176/176 (100%) | Total steps: 7040\n",
      "Rank 0 | Validation mean |  cross_entropy=0.737720 <> accuracy=0.770508 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.738683 <> accuracy=0.766016 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 41 | Metrics (epoch mean): cross_entropy=0.291500 <> acc=0.896367 | Batch (size 100): 176/176 (100%) | Total steps: 7216\n",
      "Rank 0 | Validation mean |  cross_entropy=0.743037 <> accuracy=0.769531 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.744129 <> accuracy=0.766406 | Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 42 | Metrics (epoch mean): cross_entropy=0.281574 <> acc=0.902930 | Batch (size 100): 176/176 (100%) | Total steps: 7392\n",
      "Rank 0 | Validation mean |  cross_entropy=0.748141 <> accuracy=0.770117 | Batch: 40/40 (100%)\n",
      "Rank 1 | Validation mean |  cross_entropy=0.748417 <> accuracy=0.766211 | Batch: 40/40 (100%)\n",
      "\n",
      "CPU times: user 112 ms, sys: 11.5 ms, total: 124 ms\n",
      "Wall time: 9min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "trainer_kwargs['name'] = 'codistswa'\n",
    "\n",
    "dataloader_kwargs['split_training'] = False\n",
    "dataloader_kwargs['data_parallel'] = True\n",
    "\n",
    "train_kwargs['epochs_sgd'] = 0\n",
    "train_kwargs['epochs_codist'] = 40 # codist should stop and pass to swa if codist stalls\n",
    "train_kwargs['epochs_swa'] = 15\n",
    "train_kwargs['codist_kwargs'] = {\n",
    "    # how many steps before re-syncing stale replicas\n",
    "    'sync_freq': 50,\n",
    "    # transform to apply to mean replica output\n",
    "    'transform': 'softmax',\n",
    "    # when True, prints gather and update param steps\n",
    "    'debug': False,\n",
    "}\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        swa_scheduler_kwargs,\n",
    "        seed) # seed on rank i = seed + i\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 [conda:torch]",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
