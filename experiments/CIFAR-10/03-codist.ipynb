{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 172800\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "from swadist.utils import spawn_fn\n",
    "\n",
    "# mp.spawn may throw an error without this\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "seed = (datetime.date.today() - datetime.date(2022, 4, 11)).total_seconds()\n",
    "print(f'seed: {int(seed)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-phase training: SGD + Codistillation\n",
    "\n",
    "In phase 1, we train ResNet-8 asynchronously over the whole training set using the optimal hyperparameters given in [Shallue et al. 2019](http://arxiv.org/abs/1811.03600) (SGD w/ Nesterov momentum).\n",
    "\n",
    "In phase 2, we run codistillation ([Hinton et al. 2015](http://arxiv.org/abs/1503.02531))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether to log training to Tensorboard\n",
    "log = False\n",
    "\n",
    "# number of model replicas\n",
    "world_size = 2\n",
    "\n",
    "# overall size of training minibatches, aka effective batch size\n",
    "eff_batch_size = 256\n",
    "\n",
    "# optimizer\n",
    "lr0, momentum,  = 2**-5., 0.975\n",
    "\n",
    "# scheduler\n",
    "alpha, decay_epochs = 0.25, 5\n",
    "\n",
    "# training epochs\n",
    "epochs_sgd, epochs_codist = 5, 10\n",
    "\n",
    "dataloader_kwargs = {\n",
    "    'dataset': 'cifar10',\n",
    "    'batch_size': eff_batch_size // world_size,\n",
    "    'num_workers': 4,\n",
    "    'data_parallel': True,\n",
    "}\n",
    "model_kwargs = {\n",
    "    'in_kernel_size': 3,\n",
    "    'stack_sizes': [1, 1, 1],\n",
    "    'n_classes': 10,\n",
    "    'batch_norm': False,\n",
    "}\n",
    "optimizer_kwargs = {\n",
    "    'lr': lr0,\n",
    "    'momentum': momentum,\n",
    "    'nesterov': True,\n",
    "}\n",
    "trainer_kwargs = {\n",
    "    'log': log,\n",
    "    'name': 'codist',\n",
    "}\n",
    "train_kwargs = {\n",
    "    'epochs_sgd': epochs_sgd,\n",
    "    'epochs_codist': epochs_codist,\n",
    "}\n",
    "scheduler_kwargs = {\n",
    "    'alpha': alpha,\n",
    "    'decay_epochs': decay_epochs,\n",
    "}\n",
    "\n",
    "args = (world_size,\n",
    "        dataloader_kwargs,\n",
    "        model_kwargs,\n",
    "        optimizer_kwargs,\n",
    "        trainer_kwargs,\n",
    "        train_kwargs,\n",
    "        scheduler_kwargs,\n",
    "        None, # swa_scheduler_kwargs\n",
    "        seed) # seed on rank i = seed + i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 joined process group on device cuda\n",
      "Rank 0 using seed 172800.0\n",
      "Files already downloaded and verified\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "Param preview:\n",
      "tensor([[[-0.0474,  0.0416,  0.0171],\n",
      "         [ 0.0755,  0.0522, -0.0476],\n",
      "         [ 0.0778,  0.2243,  0.0656]],\n",
      "\n",
      "        [[ 0.0514, -0.0160,  0.1759],\n",
      "         [ 0.1962, -0.1677,  0.1313],\n",
      "         [ 0.1330,  0.0804, -0.0392]],\n",
      "\n",
      "        [[ 0.1299,  0.0665,  0.1465],\n",
      "         [ 0.0598,  0.0056, -0.0290],\n",
      "         [ 0.0085, -0.2033,  0.0930]]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>) \n",
      "\n",
      "Worker 1/2 starting 15-epoch training loop...\n",
      "Random seed on rank 0: 1046294152460790038\n",
      "\n",
      "SGD epochs: 5 | Codistillation epochs: 10 | SWA epochs: 0\n",
      "DistributedDataParallel: False\n",
      "Stopping accuracy: None\n",
      "\n",
      "Rank 1 joined process group on device cuda\n",
      "Rank 1 using seed 172801.0\n",
      "Files already downloaded and verified\n",
      "Using DistributedSampler\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "Param preview:\n",
      "tensor([[[ 0.2981, -0.0035,  0.0353],\n",
      "         [-0.0600, -0.0525, -0.0593],\n",
      "         [-0.0048,  0.1072,  0.0268]],\n",
      "\n",
      "        [[ 0.1560, -0.2740, -0.1314],\n",
      "         [-0.0947, -0.0404,  0.1851],\n",
      "         [ 0.1057, -0.0919, -0.1020]],\n",
      "\n",
      "        [[-0.0563, -0.0579,  0.0372],\n",
      "         [ 0.1129,  0.1264, -0.0720],\n",
      "         [-0.0106,  0.1803, -0.0369]]], device='cuda:1',\n",
      "       grad_fn=<SelectBackward0>) \n",
      "\n",
      "Worker 2/2 starting 15-epoch training loop...\n",
      "Random seed on rank 1: 11538539991976804969\n",
      "\n",
      "Train epoch: 1 -- Accuracy: 0.256301 -- Avg. loss (cross_entropy): 1.963822 -- Batch: 176/176 (100%) -- Total steps: 176\n",
      "Validation accuracy: 0.367383 -- Avg. loss (cross_entropy): 1.680772 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 2 -- Accuracy: 0.421261 -- Avg. loss (cross_entropy): 1.560076 -- Batch: 176/176 (100%) -- Total steps: 352\n",
      "Validation accuracy: 0.491406 -- Avg. loss (cross_entropy): 1.390222 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 3 -- Accuracy: 0.520863 -- Avg. loss (cross_entropy): 1.320444 -- Batch: 176/176 (100%) -- Total steps: 528\n",
      "Validation accuracy: 0.537695 -- Avg. loss (cross_entropy): 1.274190 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 4 -- Accuracy: 0.589402 -- Avg. loss (cross_entropy): 1.154497 -- Batch: 176/176 (100%) -- Total steps: 704\n",
      "Validation accuracy: 0.601367 -- Avg. loss (cross_entropy): 1.115616 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 5 -- Accuracy: 0.633581 -- Avg. loss (cross_entropy): 1.032183 -- Batch: 176/176 (100%) -- Total steps: 880\n",
      "Validation accuracy: 0.628516 -- Avg. loss (cross_entropy): 1.071856 -- Batch: 40/40 (100%)\n",
      "\n",
      "Starting codistillation phase...\n",
      "\n",
      "Train epoch: 6 -- Accuracy: 0.662536 -- Avg. loss (cross_entropy): 0.969962 -- Batch: 176/176 (100%) -- Total steps: 1056\n",
      "Validation accuracy: 0.610938 -- Avg. loss (cross_entropy): 1.205150 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 7 -- Accuracy: 0.682116 -- Avg. loss (cross_entropy): 0.932819 -- Batch: 176/176 (100%) -- Total steps: 1232\n",
      "Validation accuracy: 0.656055 -- Avg. loss (cross_entropy): 1.108622 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 8 -- Accuracy: 0.698782 -- Avg. loss (cross_entropy): 0.886462 -- Batch: 176/176 (100%) -- Total steps: 1408\n",
      "Validation accuracy: 0.662695 -- Avg. loss (cross_entropy): 1.039171 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 9 -- Accuracy: 0.715877 -- Avg. loss (cross_entropy): 0.834205 -- Batch: 176/176 (100%) -- Total steps: 1584\n",
      "Validation accuracy: 0.674023 -- Avg. loss (cross_entropy): 1.050056 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 10 -- Accuracy: 0.727559 -- Avg. loss (cross_entropy): 0.798757 -- Batch: 176/176 (100%) -- Total steps: 1760\n",
      "Validation accuracy: 0.660547 -- Avg. loss (cross_entropy): 1.065991 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 11 -- Accuracy: 0.734755 -- Avg. loss (cross_entropy): 0.775139 -- Batch: 176/176 (100%) -- Total steps: 1936\n",
      "Validation accuracy: 0.662500 -- Avg. loss (cross_entropy): 1.084066 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 12 -- Accuracy: 0.748565 -- Avg. loss (cross_entropy): 0.735357 -- Batch: 176/176 (100%) -- Total steps: 2112\n",
      "Validation accuracy: 0.665625 -- Avg. loss (cross_entropy): 1.093231 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 13 -- Accuracy: 0.759838 -- Avg. loss (cross_entropy): 0.702046 -- Batch: 176/176 (100%) -- Total steps: 2288\n",
      "Validation accuracy: 0.671680 -- Avg. loss (cross_entropy): 1.054926 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 14 -- Accuracy: 0.769327 -- Avg. loss (cross_entropy): 0.673257 -- Batch: 176/176 (100%) -- Total steps: 2464\n",
      "Validation accuracy: 0.676562 -- Avg. loss (cross_entropy): 1.102174 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 15 -- Accuracy: 0.774405 -- Avg. loss (cross_entropy): 0.653451 -- Batch: 176/176 (100%) -- Total steps: 2640\n",
      "Validation accuracy: 0.681836 -- Avg. loss (cross_entropy): 1.050826 -- Batch: 40/40 (100%)\n",
      "\n",
      "CPU times: user 98.4 ms, sys: 38.8 ms, total: 137 ms\n",
      "Wall time: 13min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-phase training: SGD + Codistillation w/ data partitioning\n",
    "\n",
    "As before, but this time we train each model replica on disjoint partitions of the training set in phase 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 joined process group on device cuda\n",
      "Rank 0 using seed 172800.0\n",
      "Files already downloaded and verified\n",
      "Using SubsetRandomSampler with samples 0 to 22499\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "Param preview:\n",
      "tensor([[[-0.0474,  0.0416,  0.0171],\n",
      "         [ 0.0755,  0.0522, -0.0476],\n",
      "         [ 0.0778,  0.2243,  0.0656]],\n",
      "\n",
      "        [[ 0.0514, -0.0160,  0.1759],\n",
      "         [ 0.1962, -0.1677,  0.1313],\n",
      "         [ 0.1330,  0.0804, -0.0392]],\n",
      "\n",
      "        [[ 0.1299,  0.0665,  0.1465],\n",
      "         [ 0.0598,  0.0056, -0.0290],\n",
      "         [ 0.0085, -0.2033,  0.0930]]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>) \n",
      "\n",
      "Worker 1/2 starting 15-epoch training loop...\n",
      "Random seed on rank 0: 16542267418990546344\n",
      "\n",
      "SGD epochs: 5 | Codistillation epochs: 10 | SWA epochs: 0\n",
      "DistributedDataParallel: False\n",
      "Stopping accuracy: None\n",
      "\n",
      "Rank 1 joined process group on device cuda\n",
      "Rank 1 using seed 172801.0\n",
      "Files already downloaded and verified\n",
      "Using SubsetRandomSampler with samples 22500 to 44999\n",
      "Number of training samples: 45000\n",
      "Number of training batches: 176\n",
      "\n",
      "Param preview:\n",
      "tensor([[[ 0.2981, -0.0035,  0.0353],\n",
      "         [-0.0600, -0.0525, -0.0593],\n",
      "         [-0.0048,  0.1072,  0.0268]],\n",
      "\n",
      "        [[ 0.1560, -0.2740, -0.1314],\n",
      "         [-0.0947, -0.0404,  0.1851],\n",
      "         [ 0.1057, -0.0919, -0.1020]],\n",
      "\n",
      "        [[-0.0563, -0.0579,  0.0372],\n",
      "         [ 0.1129,  0.1264, -0.0720],\n",
      "         [-0.0106,  0.1803, -0.0369]]], device='cuda:1',\n",
      "       grad_fn=<SelectBackward0>) \n",
      "\n",
      "Worker 2/2 starting 15-epoch training loop...\n",
      "Random seed on rank 1: 6695891094538971562\n",
      "\n",
      "Train epoch: 1 -- Accuracy: 0.281044 -- Avg. loss (cross_entropy): 1.921902 -- Batch: 176/176 (100%) -- Total steps: 176\n",
      "Validation accuracy: 0.386523 -- Avg. loss (cross_entropy): 1.652107 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 2 -- Accuracy: 0.456836 -- Avg. loss (cross_entropy): 1.480787 -- Batch: 176/176 (100%) -- Total steps: 352\n",
      "Validation accuracy: 0.491211 -- Avg. loss (cross_entropy): 1.402224 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 3 -- Accuracy: 0.542681 -- Avg. loss (cross_entropy): 1.260857 -- Batch: 176/176 (100%) -- Total steps: 528\n",
      "Validation accuracy: 0.579102 -- Avg. loss (cross_entropy): 1.183665 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 4 -- Accuracy: 0.602777 -- Avg. loss (cross_entropy): 1.104769 -- Batch: 176/176 (100%) -- Total steps: 704\n",
      "Validation accuracy: 0.628906 -- Avg. loss (cross_entropy): 1.097563 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 5 -- Accuracy: 0.650616 -- Avg. loss (cross_entropy): 0.982426 -- Batch: 176/176 (100%) -- Total steps: 880\n",
      "Validation accuracy: 0.655469 -- Avg. loss (cross_entropy): 1.000954 -- Batch: 40/40 (100%)\n",
      "\n",
      "Starting codistillation phase...\n",
      "\n",
      "Train epoch: 6 -- Accuracy: 0.671490 -- Avg. loss (cross_entropy): 0.934648 -- Batch: 176/176 (100%) -- Total steps: 1056\n",
      "Validation accuracy: 0.663281 -- Avg. loss (cross_entropy): 1.040439 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 7 -- Accuracy: 0.687443 -- Avg. loss (cross_entropy): 0.894459 -- Batch: 176/176 (100%) -- Total steps: 1232\n",
      "Validation accuracy: 0.662695 -- Avg. loss (cross_entropy): 1.046509 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 8 -- Accuracy: 0.711864 -- Avg. loss (cross_entropy): 0.834116 -- Batch: 176/176 (100%) -- Total steps: 1408\n",
      "Validation accuracy: 0.667188 -- Avg. loss (cross_entropy): 1.042256 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 9 -- Accuracy: 0.722878 -- Avg. loss (cross_entropy): 0.796942 -- Batch: 176/176 (100%) -- Total steps: 1584\n",
      "Validation accuracy: 0.679883 -- Avg. loss (cross_entropy): 1.060355 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 10 -- Accuracy: 0.738333 -- Avg. loss (cross_entropy): 0.753605 -- Batch: 176/176 (100%) -- Total steps: 1760\n",
      "Validation accuracy: 0.676953 -- Avg. loss (cross_entropy): 1.014017 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 11 -- Accuracy: 0.748597 -- Avg. loss (cross_entropy): 0.729630 -- Batch: 176/176 (100%) -- Total steps: 1936\n",
      "Validation accuracy: 0.685937 -- Avg. loss (cross_entropy): 1.019050 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 12 -- Accuracy: 0.757369 -- Avg. loss (cross_entropy): 0.693342 -- Batch: 176/176 (100%) -- Total steps: 2112\n",
      "Validation accuracy: 0.694336 -- Avg. loss (cross_entropy): 0.993823 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 13 -- Accuracy: 0.773729 -- Avg. loss (cross_entropy): 0.654198 -- Batch: 176/176 (100%) -- Total steps: 2288\n",
      "Validation accuracy: 0.688477 -- Avg. loss (cross_entropy): 0.977679 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 14 -- Accuracy: 0.782765 -- Avg. loss (cross_entropy): 0.620715 -- Batch: 176/176 (100%) -- Total steps: 2464\n",
      "Validation accuracy: 0.688281 -- Avg. loss (cross_entropy): 1.022534 -- Batch: 40/40 (100%)\n",
      "\n",
      "Train epoch: 15 -- Accuracy: 0.792956 -- Avg. loss (cross_entropy): 0.598044 -- Batch: 176/176 (100%) -- Total steps: 2640\n",
      "Validation accuracy: 0.689648 -- Avg. loss (cross_entropy): 1.069239 -- Batch: 40/40 (100%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataloader_kwargs['data_parallel'] = False\n",
    "dataloader_kwargs['split_training'] = True\n",
    "trainer_kwargs['name'] = 'codist-partitioned'\n",
    "\n",
    "# begin training\n",
    "mp.spawn(spawn_fn, args=args, nprocs=world_size, join=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 [conda:torch]",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
